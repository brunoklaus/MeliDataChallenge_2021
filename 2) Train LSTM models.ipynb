{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6afbe454",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22cc1e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import create_dataset,download_dataset\n",
    "download_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725ab209",
   "metadata": {},
   "source": [
    "## Process train_data.parquet, create pytorch files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9d8f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "from dataset import create_dataset,download_dataset\n",
    "df = dataset.create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9773c1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15507/15507 [59:01<00:00,  4.38it/s] \n",
      "100%|██████████| 1728/1728 [06:13<00:00,  4.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from converted_dataset import get_converted_dataset, create_pytorch_dataset\n",
    "create_pytorch_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be607f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import DataLoader,Dataset,Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "train_L = torch.load('./dataset/converted/train.pt',map_location='cuda')\n",
    "val_L = torch.load('./dataset/converted/val.pt',map_location='cuda')\n",
    "test_L  = torch.load('./dataset/converted/test.pt',map_location='cuda')\n",
    "\n",
    "batch_size = 128\n",
    "dataloaders = {\"train\":DataLoader(train_L,batch_size=batch_size,shuffle=True),\n",
    "            \"val\":DataLoader(val_L,batch_size=batch_size,shuffle=False),\n",
    "            \"test\":DataLoader(test_L,batch_size=batch_size),\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a0dfc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import DataLoader,Dataset,Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Embedding, GRU,LSTM,Linear,ReLU, BatchNorm1d,BatchNorm2d,Conv1d, Dropout\n",
    "\n",
    "class ChallengeModel(torch.nn.Module):\n",
    "    \"\"\" 1D Convolutional Neural Network. \"\"\"\n",
    "    NAME = \"Conv1d_1\"\n",
    "    \n",
    "    def __init__(self,max_domain=2000,H1=2*256,H2=2*128,H_emb=16,\n",
    "                 use_emb=True,**kwargs):\n",
    "        super(ChallengeModel, self).__init__(**kwargs)\n",
    "        self.use_emb = use_emb\n",
    "        self.H_emb = H_emb\n",
    "        self.max_domain = max_domain\n",
    "        self.emb = Embedding(max_domain,H_emb)\n",
    "        self.lin1 = Linear(16,H1)\n",
    "        self.lin2 = Linear(H1,H2)\n",
    "        self.bn1 = BatchNorm1d(30)\n",
    "        self.lin1 = Linear(32,256)\n",
    "        self.lin2 = Linear(256,128)\n",
    "        self.lin3 = Linear(128,30)\n",
    "        self.conv1 = Conv1d(16+ H_emb if use_emb else 16, 32,kernel_size=3)\n",
    "        self.dr = Dropout(0.5)\n",
    "        self.conv2 = Conv1d(32, 64,kernel_size=3,stride=2)\n",
    "        self.conv3 = Conv1d(64, 64,kernel_size=3,stride=2)\n",
    "        self.conv4 = Conv1d(64, 16,kernel_size=3,stride=2)\n",
    "        \n",
    "        \n",
    "    def forward(self,data,hidden_size=18):\n",
    "        N, L, H_in = data.X.shape\n",
    "        \n",
    "        dom = data.domain.view(-1)\n",
    "        dom = dom.clip(0,self.max_domain-1).int()\n",
    "        emb = self.emb(dom).view(data.X.shape[0],data.X.shape[1],self.H_emb)\n",
    "        \n",
    "        x = data.X\n",
    "        x = self.bn1(x)\n",
    "        #x = F.relu(self.lin1(x))\n",
    "        #x = F.relu(self.lin2(x))\n",
    "        if self.use_emb:\n",
    "            x = torch.cat([x,emb],axis=-1)\n",
    "        \n",
    "        x = x.transpose(2,1)\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        x = F.leaky_relu(self.conv2(x))\n",
    "        x = F.leaky_relu(self.conv3(x))\n",
    "        x = F.leaky_relu(self.conv4(x))\n",
    "        x = x.reshape(N,-1)\n",
    "        x = self.dr(x)\n",
    "        x = F.leaky_relu(self.lin1(x))\n",
    "        x = self.dr(x)\n",
    "        x = F.leaky_relu(self.lin2(x))\n",
    "        x = self.lin3(x)\n",
    "        \n",
    "\n",
    "        probs = F.softmax(x,dim=1)\n",
    "        \n",
    "        return probs\n",
    "        \n",
    "\n",
    "class ChallengeModel(torch.nn.Module):\n",
    "    NAME = \"LSTM11\"\n",
    "\n",
    "    def __init__(self,max_domain=8050,H1=256,H2=128,H_emb=32,\n",
    "                 use_emb=False,**kwargs):\n",
    "        super(ChallengeModel, self).__init__(**kwargs)\n",
    "        self.use_emb = use_emb\n",
    "        self.H_emb = H_emb\n",
    "        self.max_domain = max_domain\n",
    "        self.emb = Embedding(max_domain,H_emb)\n",
    "\n",
    "        self.lin1 = Linear(16,H1)\n",
    "        self.lin2 = Linear(H1,H2)\n",
    "\n",
    "        self.lstm = LSTM(input_size= H2 + H_emb if use_emb else H2,\n",
    "                       hidden_size=32,\n",
    "                        num_layers=1,\n",
    "                       batch_first=True)\n",
    "        self.lin3 = Linear(50,512)\n",
    "        self.lin4 = Linear(512,30)\n",
    "\n",
    "    def forward(self,data,hidden_size=18):\n",
    "        N, L, H_in = data.X.shape\n",
    "        X  = sample.X[:,:24,:]\n",
    "        \n",
    "        \n",
    "        \"\"\" Compute some bonus Features\"\"\"\n",
    "        minutes_active = X[:,:,11].view(N,24)\n",
    "        minutes_active = torch.cat([torch.ones(N,1),minutes_active.cpu()],axis=1).int()\n",
    "        days_inactive = torch.max(torch.FloatTensor(minutes_active.numpy()[:,::-1].copy()).cuda(),axis=1)[1]\n",
    "        items_sold = torch.clip(X[:,:,0].view(N,24),0.,1.)\n",
    "        items_sold = torch.cat([torch.ones(N,1),items_sold.cpu()],axis=1).int()\n",
    "        days_no_sold = torch.max(torch.FloatTensor(items_sold.numpy()[:,::-1].copy()).cuda(),axis=1)[1]\n",
    "        fixed_feats = X[:,0,[2,3,4,5,6,7,8,9,10,13,15]]\n",
    "        var_feats = X[:,:,[0,1,11,12,14]]\n",
    "        summ_feats = torch.cat([fixed_feats,var_feats.mean(axis=1),\n",
    "                                days_inactive.view(-1,1)/30.0,\n",
    "                                days_no_sold.view(-1,1)/30.0],axis=1)\n",
    "        \n",
    "        \"\"\" Try to embed the domain id. \"\"\"\n",
    "        dom = data.domain.view(-1)\n",
    "        dom = dom.clip(0,self.max_domain-1).int()\n",
    "        emb = self.emb(dom).view(data.X.shape[0],data.X.shape[1],self.H_emb)\n",
    "\n",
    "        x = F.relu(self.lin1(X))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        all_outs, (last_output, _) =  self.lstm(x) #(N,L,30)\n",
    "        \n",
    "        x = last_output.squeeze(0)\n",
    "        x = torch.cat([x,summ_feats],axis=-1)\n",
    "        x = F.relu(self.lin3(x))\n",
    "        x = self.lin4(x)\n",
    "        probs = F.softmax(x,dim=1)\n",
    "\n",
    "        return probs\n",
    "    \n",
    "    \n",
    "\n",
    "import torch.nn as nn\n",
    "class RNNEncoder(nn.Module):\n",
    "    def __init__(self, rnn_num_layers=1, input_feature_len=18, sequence_len=30, hidden_size=100, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.sequence_len = sequence_len\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_feature_len = input_feature_len\n",
    "        self.num_layers = rnn_num_layers\n",
    "        self.rnn_directions = 2 if bidirectional else 1\n",
    "        self.gru = nn.GRU(\n",
    "            num_layers = rnn_num_layers,\n",
    "            input_size=input_feature_len,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        \n",
    "    def forward(self, input_seq):\n",
    "        ht = torch.zeros(self.num_layers * self.rnn_directions, input_seq.size(0) , self.hidden_size, device='cuda')\n",
    "        if input_seq.ndim < 3:\n",
    "            input_seq.unsqueeze_(2)\n",
    "        gru_out, hidden = self.gru(input_seq, ht)\n",
    "        if self.rnn_directions > 1:\n",
    "            gru_out = gru_out.view(input_seq.size(0), self.sequence_len, self.rnn_directions, self.hidden_size)\n",
    "            gru_out = torch.sum(gru_out, axis=2)\n",
    "        return gru_out, hidden.squeeze(0)\n",
    "    \n",
    "class AttentionDecoderCell(nn.Module):\n",
    "    def __init__(self, input_feature_len, hidden_size, sequence_len):\n",
    "        super().__init__()\n",
    "        # attention - inputs - (decoder_inputs, prev_hidden)\n",
    "        self.attention_linear = nn.Linear(hidden_size, sequence_len)\n",
    "        # attention_combine - inputs - (decoder_inputs, attention * encoder_outputs)\n",
    "        self.decoder_rnn_cell = nn.GRUCell(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "        )\n",
    "        self.out = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, encoder_output, prev_hidden, y):\n",
    "        attention_input = prev_hidden\n",
    "        attention_weights = F.softmax(self.attention_linear(attention_input)).unsqueeze(1)\n",
    "        attention_combine = torch.bmm(attention_weights, encoder_output).squeeze(1)\n",
    "        rnn_hidden = self.decoder_rnn_cell(attention_combine, prev_hidden)\n",
    "        output = self.out(rnn_hidden)\n",
    "        return output, rnn_hidden\n",
    "\n",
    "\n",
    "class EncoderDecoderWrapper(nn.Module):\n",
    "    NAME = \"RNN_And_Att2\"\n",
    "    def __init__(self, encoder, decoder_cell, output_size=30, teacher_forcing=0.3):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder_cell = decoder_cell\n",
    "        self.output_size = output_size\n",
    "        self.teacher_forcing = teacher_forcing\n",
    "        \n",
    "    def train(self):\n",
    "        self.encoder.train()\n",
    "        self.decoder_cell.train()\n",
    "        \n",
    "    def eval(self):\n",
    "        self.encoder.eval()\n",
    "        self.decoder_cell.eval()\n",
    "        \n",
    "    def state_dict(self):\n",
    "        return {\n",
    "            'encoder': self.encoder.state_dict(),\n",
    "            'decoder_cell': self.decoder_cell.state_dict()\n",
    "        }\n",
    "    \n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.encoder.load_state_dict(state_dict['encoder'])\n",
    "        self.decoder_cell.load_state_dict(state_dict['decoder_cell'])\n",
    "\n",
    "    def __call__(self, data):\n",
    "        xb = data.X.clone()\n",
    "        yb = None\n",
    "        input_seq = xb\n",
    "        encoder_output, encoder_hidden = self.encoder(input_seq)\n",
    "        prev_hidden = encoder_hidden\n",
    "        if torch.cuda.is_available():\n",
    "            outputs = torch.zeros(input_seq.size(0), self.output_size, device='cuda')\n",
    "        else:\n",
    "            outputs = torch.zeros(input_seq.size(0), self.output_size)\n",
    "        y_prev = input_seq[:, -1, :]\n",
    "        for i in range(self.output_size):\n",
    "            if (yb is not None) and (i > 0) and (torch.rand(1) < self.teacher_forcing):\n",
    "                y_prev = yb[:, i].unsqueeze(1)\n",
    "            rnn_output, prev_hidden = self.decoder_cell(encoder_output, prev_hidden, y_prev)\n",
    "            y_prev = rnn_output\n",
    "            outputs[:, i] = rnn_output.squeeze(1)\n",
    "        return F.softmax(outputs,dim=1)              \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0307d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2586 [00:00<?, ?it/s]<ipython-input-2-e67f319914ba>:166: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  attention_weights = F.softmax(self.attention_linear(attention_input)).unsqueeze(1)\n",
      "100%|██████████| 2586/2586 [01:03<00:00, 41.03it/s]\n",
      "  3%|▎         | 10/289 [00:00<00:02, 94.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss (train): 3.652901313421068\n",
      "Flushed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 289/289 [00:03<00:00, 92.64it/s]\n",
      "  0%|          | 4/2586 [00:00<01:11, 35.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best\n",
      "Avg loss (val): 3.496710292195779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2586/2586 [01:03<00:00, 40.95it/s]\n",
      "  3%|▎         | 10/289 [00:00<00:03, 90.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss (train): 3.5225263421883994\n",
      "Flushed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 289/289 [00:03<00:00, 91.88it/s]\n",
      "  0%|          | 4/2586 [00:00<01:11, 35.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss (val): 3.535823569578283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2586/2586 [01:03<00:00, 41.00it/s]\n",
      "  3%|▎         | 9/289 [00:00<00:03, 89.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss (train): 3.506158452852696\n",
      "Flushed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 289/289 [00:03<00:00, 91.07it/s]\n",
      "  0%|          | 4/2586 [00:00<01:10, 36.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best\n",
      "Avg loss (val): 3.477471974481761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2586/2586 [01:02<00:00, 41.08it/s]\n",
      "  3%|▎         | 9/289 [00:00<00:03, 88.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss (train): 3.4953327621495363\n",
      "Flushed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 289/289 [00:03<00:00, 90.46it/s]\n",
      "  0%|          | 4/2586 [00:00<01:12, 35.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss (val): 3.500893929425408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2586/2586 [01:01<00:00, 41.74it/s]\n",
      "  3%|▎         | 10/289 [00:00<00:03, 91.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss (train): 3.4855258702678635\n",
      "Flushed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 289/289 [00:03<00:00, 91.10it/s]\n",
      "  0%|          | 4/2586 [00:00<01:11, 36.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best\n",
      "Avg loss (val): 3.462600800405324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2586/2586 [01:03<00:00, 40.97it/s]\n",
      "  3%|▎         | 9/289 [00:00<00:03, 89.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss (train): 3.4773926942365074\n",
      "Flushed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 289/289 [00:03<00:00, 92.70it/s]\n",
      "  0%|          | 4/2586 [00:00<01:10, 36.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss (val): 3.4733296884384948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2586/2586 [01:03<00:00, 40.82it/s]\n",
      "  3%|▎         | 9/289 [00:00<00:03, 89.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss (train): 3.472115393304493\n",
      "Flushed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 289/289 [00:03<00:00, 92.35it/s]\n",
      "  0%|          | 4/2586 [00:00<01:11, 36.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best\n",
      "Avg loss (val): 3.4496319359974055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2586/2586 [01:03<00:00, 40.88it/s]\n",
      "  3%|▎         | 9/289 [00:00<00:03, 87.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss (train): 3.46602983126231\n",
      "Flushed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 289/289 [00:03<00:00, 90.87it/s]\n",
      "  0%|          | 4/2586 [00:00<01:10, 36.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best\n",
      "Avg loss (val): 3.4482466473298916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2586/2586 [01:03<00:00, 40.80it/s]\n",
      "  3%|▎         | 9/289 [00:00<00:03, 89.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss (train): 3.4614534757898836\n",
      "Flushed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 289/289 [00:03<00:00, 91.58it/s]\n",
      "  0%|          | 4/2586 [00:00<01:12, 35.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss (val): 3.4530019273394945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2586/2586 [01:02<00:00, 41.24it/s]\n",
      "  3%|▎         | 10/289 [00:00<00:03, 90.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss (train): 3.456699606253026\n",
      "Flushed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 289/289 [00:03<00:00, 92.35it/s]\n",
      "  0%|          | 4/2586 [00:00<01:11, 35.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best\n",
      "Avg loss (val): 3.439727942423837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2586/2586 [01:03<00:00, 41.00it/s]\n",
      "  3%|▎         | 9/289 [00:00<00:03, 89.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss (train): 3.4538156360226457\n",
      "Flushed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 289/289 [00:03<00:00, 91.57it/s]\n",
      "  0%|          | 4/2586 [00:00<01:12, 35.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss (val): 3.463597517112547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2586/2586 [01:03<00:00, 40.93it/s]\n",
      "  3%|▎         | 10/289 [00:00<00:03, 92.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss (train): 3.449124423736578\n",
      "Flushed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 289/289 [00:03<00:00, 93.68it/s]\n",
      "  0%|          | 4/2586 [00:00<01:10, 36.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss (val): 3.4465995577379904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2586/2586 [01:03<00:00, 40.88it/s]\n",
      "  3%|▎         | 9/289 [00:00<00:03, 88.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss (train): 3.4455667271322734\n",
      "Flushed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 289/289 [00:03<00:00, 92.93it/s]\n",
      "  0%|          | 4/2586 [00:00<01:10, 36.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best\n",
      "Avg loss (val): 3.4386559250445514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 2243/2586 [00:55<00:08, 40.65it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b8d837c0c76b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0mloss_xent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loss/{mode}\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gcn2/lib/python3.9/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gcn2/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm,trange\n",
    "from torch.nn import MSELoss\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "NLLLoss = torch.nn.NLLLoss()\n",
    "def custom_MSE(preds,actuals):\n",
    "    preds = torch.cumsum(preds,dim=1).float()\n",
    "    actuals = actuals.float()\n",
    "    return 30.0*torch.mean(torch.square(preds-actuals))\n",
    "def XENT(preds,actuals):\n",
    "    preds = torch.log(preds)\n",
    "    actuals = torch.argmax(actuals,dim=1)\n",
    "    return NLLLoss(preds,actuals)\n",
    "\n",
    "\"\"\"\n",
    "    SELECT YOUR MODEL HERE\n",
    "\"\"\"\n",
    "enc = RNNEncoder(1,16,30,100).cuda()\n",
    "dec= AttentionDecoderCell(16,100,30).cuda()\n",
    "model = EncoderDecoderWrapper(enc,dec)\n",
    "#model = ChallengeModel().cuda()\n",
    "\n",
    "writer = SummaryWriter()\n",
    "num_epochs = 100\n",
    "opt = torch.optim.Adam(lr=5e-4,params=model.parameters())\n",
    "step = 0\n",
    "\n",
    "lr_sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt,factor=0.5,patience=100,verbose=True)\n",
    "\n",
    "torch.cuda.manual_seed(42)\n",
    "lowest_loss = 9999\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "dataloaders = {\"train\":DataLoader(train_L,batch_size=batch_size,shuffle=True),\n",
    "            \"val\":DataLoader(val_L,batch_size=batch_size,shuffle=False),\n",
    "            \"test\":DataLoader(test_L,batch_size=batch_size),\n",
    "           }\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    running_loss = {\"train\":[],\"val\":[]}\n",
    "    for mode in ['train','val']:\n",
    "        if mode == 'train':\n",
    "                model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "        for i,sample in tqdm(enumerate(dataloaders[mode]),total=len(dataloaders[mode])):\n",
    "            out = model(sample)\n",
    "            loss = custom_MSE(out,sample.target)\n",
    "            loss_xent = XENT(out,sample.target)\n",
    "            \n",
    "            loss_np = loss.clone().detach().cpu().item()\n",
    "            running_loss[mode].append(loss_np)\n",
    "\n",
    "            if mode == 'train':\n",
    "                opt.zero_grad()\n",
    "                loss_xent.backward()\n",
    "                opt.step()\n",
    "        writer.add_scalar(f\"Loss/{mode}\",  sum(running_loss[mode])/len(running_loss[mode]), step)\n",
    "        if mode == 'val' and sum(running_loss[mode])/len(running_loss[mode]) < lowest_loss:\n",
    "            os.makedirs(f'./model/{model.NAME}',exist_ok=True)\n",
    "            torch.save(model.state_dict(),f'./model/{model.NAME}/best_model.pt')\n",
    "            lowest_loss = sum(running_loss[mode])/len(running_loss[mode])\n",
    "            print(\"New best\")\n",
    "\n",
    "        print(f\"Avg loss ({mode}): {sum(running_loss[mode])/len(running_loss[mode])}\")\n",
    "\n",
    "        if mode == 'train':\n",
    "            step += 1\n",
    "            torch.cuda.empty_cache()\n",
    "            writer.flush()\n",
    "            print(\"Flushed\")\n",
    "            import os\n",
    "            os.makedirs(f'./model/{model.NAME}',exist_ok=True)\n",
    "            if i%50 == 0:\n",
    "                torch.save(model.state_dict(),f'./model/{model.NAME}/model_{step}.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1378b395",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/289 [00:00<?, ?it/s]<ipython-input-2-e67f319914ba>:166: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  attention_weights = F.softmax(self.attention_linear(attention_input)).unsqueeze(1)\n",
      "100%|██████████| 289/289 [00:03<00:00, 76.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36938, 30)\n",
      "[[0.031 0.042 0.043 ... 0.02  0.019 0.019]\n",
      " [0.26  0.136 0.101 ... 0.001 0.001 0.001]\n",
      " [0.005 0.011 0.018 ... 0.024 0.023 0.021]\n",
      " ...\n",
      " [0.334 0.295 0.147 ... 0.    0.    0.   ]\n",
      " [0.052 0.064 0.064 ... 0.005 0.004 0.004]\n",
      " [0.011 0.02  0.027 ... 0.018 0.017 0.015]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.260</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.353</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36933</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36934</th>\n",
       "      <td>0.033</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36935</th>\n",
       "      <td>0.334</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36936</th>\n",
       "      <td>0.052</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36937</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36938 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2      3      4      5      6      7      8      9   \\\n",
       "0      0.031  0.042  0.043  0.042  0.044  0.046  0.047  0.047  0.045  0.043   \n",
       "1      0.260  0.136  0.101  0.094  0.090  0.078  0.057  0.039  0.028  0.021   \n",
       "2      0.005  0.011  0.018  0.027  0.036  0.044  0.047  0.046  0.044  0.042   \n",
       "3      0.353  0.329  0.158  0.075  0.034  0.016  0.007  0.004  0.003  0.002   \n",
       "4      0.011  0.026  0.035  0.046  0.062  0.071  0.070  0.063  0.054  0.048   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "36933  0.002  0.004  0.006  0.009  0.015  0.023  0.033  0.039  0.040  0.038   \n",
       "36934  0.033  0.048  0.053  0.062  0.076  0.082  0.076  0.065  0.054  0.046   \n",
       "36935  0.334  0.295  0.147  0.088  0.057  0.033  0.016  0.008  0.004  0.003   \n",
       "36936  0.052  0.064  0.064  0.073  0.085  0.088  0.079  0.066  0.054  0.045   \n",
       "36937  0.011  0.020  0.027  0.034  0.046  0.057  0.062  0.059  0.053  0.047   \n",
       "\n",
       "       ...     20     21     22     23     24     25     26     27     28  \\\n",
       "0      ...  0.027  0.026  0.024  0.023  0.023  0.022  0.021  0.020  0.019   \n",
       "1      ...  0.002  0.002  0.002  0.002  0.001  0.001  0.001  0.001  0.001   \n",
       "2      ...  0.035  0.033  0.030  0.028  0.027  0.026  0.025  0.024  0.023   \n",
       "3      ...  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001  0.001   \n",
       "4      ...  0.023  0.021  0.018  0.016  0.015  0.014  0.013  0.012  0.011   \n",
       "...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "36933  ...  0.045  0.044  0.039  0.034  0.030  0.028  0.028  0.028  0.027   \n",
       "36934  ...  0.017  0.015  0.013  0.011  0.010  0.009  0.008  0.007  0.007   \n",
       "36935  ...  0.001  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "36936  ...  0.012  0.010  0.009  0.008  0.007  0.006  0.005  0.005  0.004   \n",
       "36937  ...  0.028  0.025  0.023  0.021  0.020  0.019  0.019  0.018  0.017   \n",
       "\n",
       "          29  \n",
       "0      0.019  \n",
       "1      0.001  \n",
       "2      0.021  \n",
       "3      0.001  \n",
       "4      0.010  \n",
       "...      ...  \n",
       "36933  0.025  \n",
       "36934  0.006  \n",
       "36935  0.000  \n",
       "36936  0.004  \n",
       "36937  0.015  \n",
       "\n",
       "[36938 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4309 [00:00<?, ?it/s]<ipython-input-2-e67f319914ba>:166: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  attention_weights = F.softmax(self.attention_linear(attention_input)).unsqueeze(1)\n",
      "100%|██████████| 4309/4309 [00:49<00:00, 87.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(551472, 30)\n",
      "[[0.005 0.011 0.017 ... 0.02  0.018 0.016]\n",
      " [0.003 0.008 0.015 ... 0.016 0.015 0.014]\n",
      " [0.051 0.175 0.188 ... 0.005 0.004 0.004]\n",
      " ...\n",
      " [0.004 0.008 0.013 ... 0.035 0.035 0.035]\n",
      " [0.022 0.03  0.037 ... 0.023 0.022 0.021]\n",
      " [0.001 0.002 0.003 ... 0.062 0.063 0.064]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.051</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551467</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551468</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551469</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551470</th>\n",
       "      <td>0.022</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551471</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>551472 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2      3      4      5      6      7      8      9   \\\n",
       "0       0.005  0.011  0.017  0.024  0.035  0.046  0.053  0.053  0.050  0.046   \n",
       "1       0.003  0.008  0.015  0.025  0.041  0.056  0.065  0.065  0.059  0.053   \n",
       "2       0.051  0.175  0.188  0.162  0.114  0.069  0.040  0.025  0.018  0.015   \n",
       "3       0.010  0.024  0.040  0.058  0.078  0.087  0.084  0.074  0.062  0.052   \n",
       "4       0.001  0.003  0.005  0.010  0.017  0.026  0.033  0.036  0.036  0.035   \n",
       "...       ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "551467  0.004  0.006  0.010  0.015  0.021  0.026  0.030  0.033  0.035  0.037   \n",
       "551468  0.002  0.004  0.007  0.011  0.015  0.020  0.024  0.027  0.029  0.031   \n",
       "551469  0.004  0.008  0.013  0.019  0.025  0.031  0.034  0.037  0.039  0.040   \n",
       "551470  0.022  0.030  0.037  0.043  0.047  0.050  0.049  0.046  0.042  0.039   \n",
       "551471  0.001  0.002  0.003  0.005  0.007  0.010  0.012  0.014  0.016  0.019   \n",
       "\n",
       "        ...     20     21     22     23     24     25     26     27     28  \\\n",
       "0       ...  0.034  0.031  0.027  0.024  0.022  0.021  0.021  0.020  0.018   \n",
       "1       ...  0.028  0.025  0.022  0.019  0.018  0.017  0.017  0.016  0.015   \n",
       "2       ...  0.006  0.006  0.006  0.005  0.005  0.005  0.005  0.005  0.004   \n",
       "3       ...  0.017  0.015  0.013  0.012  0.011  0.011  0.011  0.010  0.009   \n",
       "4       ...  0.044  0.041  0.037  0.035  0.035  0.036  0.037  0.035  0.033   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "551467  ...  0.040  0.039  0.038  0.038  0.037  0.036  0.036  0.035  0.035   \n",
       "551468  ...  0.044  0.044  0.044  0.044  0.044  0.043  0.043  0.042  0.042   \n",
       "551469  ...  0.036  0.036  0.035  0.035  0.035  0.035  0.035  0.035  0.035   \n",
       "551470  ...  0.030  0.029  0.028  0.027  0.026  0.025  0.024  0.023  0.022   \n",
       "551471  ...  0.049  0.051  0.053  0.055  0.057  0.059  0.060  0.062  0.063   \n",
       "\n",
       "           29  \n",
       "0       0.016  \n",
       "1       0.014  \n",
       "2       0.004  \n",
       "3       0.009  \n",
       "4       0.031  \n",
       "...       ...  \n",
       "551467  0.035  \n",
       "551468  0.041  \n",
       "551469  0.035  \n",
       "551470  0.021  \n",
       "551471  0.064  \n",
       "\n",
       "[551472 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm,trange\n",
    "from torch.nn import MSELoss\n",
    "import numpy as np\n",
    "\n",
    "#model = ChallengeModel().cuda()\n",
    "model.load_state_dict(torch.load(f'./model/{model.NAME}/best_model.pt'))\n",
    "\n",
    "for mode in ['val','test']:\n",
    "    torch.cuda.empty_cache()\n",
    "    L = []\n",
    "    model.eval()\n",
    "    for i,sample in tqdm(enumerate(dataloaders[mode]),\n",
    "                             total=len(dataloaders[mode]) ):\n",
    "        out = model(sample)\n",
    "        L.append(out.clone().detach().cpu())\n",
    "    L = torch.cat(L,axis=0)\n",
    "    L = L.cpu().numpy()\n",
    "    L = np.round(L,decimals=3)\n",
    "    print(L.shape)\n",
    "    print(L)    \n",
    "    import pandas as pd\n",
    "    out_df = pd.DataFrame(L)\n",
    "    display(out_df)\n",
    "    out_df.to_csv(f'./preds/{model.NAME}_{mode}.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bfa69df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.177</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551467</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551468</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551469</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551470</th>\n",
       "      <td>0.018</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551471</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>551472 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2      3      4      5      6      7      8      9   \\\n",
       "0       0.008  0.017  0.023  0.028  0.045  0.052  0.058  0.061  0.054  0.054   \n",
       "1       0.007  0.017  0.024  0.034  0.055  0.064  0.075  0.072  0.060  0.059   \n",
       "2       0.177  0.211  0.165  0.107  0.090  0.066  0.043  0.029  0.019  0.018   \n",
       "3       0.038  0.056  0.064  0.077  0.094  0.106  0.085  0.061  0.061  0.039   \n",
       "4       0.002  0.003  0.006  0.009  0.013  0.020  0.025  0.035  0.028  0.039   \n",
       "...       ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "551467  0.006  0.010  0.009  0.015  0.015  0.026  0.026  0.025  0.022  0.025   \n",
       "551468  0.006  0.009  0.008  0.014  0.014  0.024  0.024  0.023  0.019  0.024   \n",
       "551469  0.008  0.013  0.013  0.019  0.021  0.032  0.034  0.028  0.034  0.031   \n",
       "551470  0.018  0.023  0.025  0.033  0.038  0.054  0.053  0.042  0.053  0.042   \n",
       "551471  0.004  0.006  0.006  0.010  0.009  0.018  0.018  0.020  0.015  0.020   \n",
       "\n",
       "        ...     20     21     22     23     24     25     26     27     28  \\\n",
       "0       ...  0.026  0.027  0.018  0.018  0.014  0.017  0.015  0.018  0.009   \n",
       "1       ...  0.021  0.023  0.015  0.015  0.011  0.014  0.011  0.016  0.008   \n",
       "2       ...  0.002  0.002  0.002  0.001  0.002  0.001  0.002  0.002  0.001   \n",
       "3       ...  0.011  0.010  0.008  0.006  0.008  0.009  0.007  0.008  0.004   \n",
       "4       ...  0.044  0.043  0.037  0.034  0.027  0.036  0.037  0.037  0.037   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "551467  ...  0.047  0.044  0.048  0.034  0.038  0.046  0.055  0.052  0.047   \n",
       "551468  ...  0.048  0.045  0.048  0.036  0.039  0.047  0.059  0.055  0.049   \n",
       "551469  ...  0.040  0.041  0.047  0.027  0.036  0.042  0.035  0.039  0.037   \n",
       "551470  ...  0.030  0.031  0.035  0.018  0.021  0.028  0.020  0.024  0.022   \n",
       "551471  ...  0.052  0.047  0.048  0.041  0.043  0.051  0.071  0.061  0.058   \n",
       "\n",
       "           29  \n",
       "0       0.012  \n",
       "1       0.010  \n",
       "2       0.002  \n",
       "3       0.006  \n",
       "4       0.034  \n",
       "...       ...  \n",
       "551467  0.050  \n",
       "551468  0.054  \n",
       "551469  0.034  \n",
       "551470  0.019  \n",
       "551471  0.062  \n",
       "\n",
       "[551472 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a281770",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f2b2d035213e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#import tweedie\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m for i,sample in tqdm(enumerate(dataloaders['train']),\n\u001b[1;32m      5\u001b[0m                          total=len(dataloaders['train']) ):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#import tweedie\n",
    "L = []\n",
    "model.eval()\n",
    "for i,sample in tqdm(enumerate(dataloaders['train']),\n",
    "                         total=len(dataloaders['train']) ):\n",
    "    out = model(sample)\n",
    "    temp = sample.target.clone().detach().cpu()\n",
    "    L.append(np.argmax(temp,axis=1))\n",
    "    \n",
    "L = torch.cat(L)\n",
    "L = L.cpu().numpy()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.hist(L,bins=30)\n",
    "ax.set_xticks(np.arange(31))\n",
    "ax.grid()\n",
    "fig.show()\n",
    "#L = np.round(L,decimals=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ac9ede2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-c53536396de8>:8: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ef8d4c99df0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.set_xticks(np.arange(31))\n",
    "ax.grid()\n",
    "fig.show()\n",
    "df1 = pd.read_csv('./ensemble.csv.gz',header=None)\n",
    "\n",
    "\n",
    "val_labels = torch.cat([el.target.view(-1,30) for el in torch.load('./dataset/converted/val.pt',map_location='cuda')],\n",
    "                 axis=0).cpu().numpy()\n",
    "\n",
    "plt.plot(np.arange(30),np.mean(df1.values.cumsum(axis=1),axis=0),c='blue')\n",
    "\n",
    "plt.plot(np.arange(30),np.mean(val_labels,axis=0),c='green')\n",
    "#df = pd.read_csv('./LSTM2.csv.gz',header=None)\n",
    "#ax.plot(np.arange(30),np.mean(df.values,axis=0),c='red')\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5db4fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.214</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.042</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551467</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551468</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551469</th>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551470</th>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551471</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>551472 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2      3      4      5      6      7      8      9   \\\n",
       "0       0.005  0.006  0.011  0.015  0.026  0.037  0.046  0.051  0.041  0.045   \n",
       "1       0.005  0.009  0.015  0.021  0.036  0.054  0.060  0.068  0.051  0.053   \n",
       "2       0.214  0.186  0.155  0.102  0.093  0.053  0.042  0.024  0.018  0.017   \n",
       "3       0.042  0.046  0.064  0.062  0.088  0.096  0.075  0.062  0.056  0.046   \n",
       "4       0.006  0.006  0.010  0.012  0.021  0.026  0.035  0.035  0.036  0.037   \n",
       "...       ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "551467  0.006  0.005  0.007  0.010  0.013  0.014  0.022  0.021  0.027  0.024   \n",
       "551468  0.006  0.005  0.007  0.010  0.014  0.014  0.022  0.021  0.027  0.024   \n",
       "551469  0.007  0.007  0.008  0.012  0.016  0.016  0.025  0.023  0.029  0.026   \n",
       "551470  0.016  0.017  0.021  0.023  0.030  0.032  0.040  0.038  0.037  0.037   \n",
       "551471  0.005  0.004  0.006  0.009  0.012  0.013  0.021  0.020  0.025  0.023   \n",
       "\n",
       "        ...     20     21     22     23     24     25     26     27     28  \\\n",
       "0       ...  0.037  0.034  0.027  0.024  0.024  0.024  0.022  0.023  0.020   \n",
       "1       ...  0.031  0.026  0.020  0.018  0.017  0.017  0.016  0.013  0.013   \n",
       "2       ...  0.004  0.002  0.002  0.003  0.001  0.001  0.002  0.001  0.001   \n",
       "3       ...  0.015  0.012  0.009  0.010  0.007  0.009  0.008  0.005  0.007   \n",
       "4       ...  0.042  0.039  0.036  0.032  0.029  0.033  0.031  0.034  0.028   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "551467  ...  0.048  0.046  0.045  0.043  0.042  0.048  0.049  0.054  0.047   \n",
       "551468  ...  0.047  0.045  0.045  0.043  0.042  0.048  0.049  0.054  0.048   \n",
       "551469  ...  0.045  0.044  0.043  0.041  0.041  0.046  0.046  0.050  0.045   \n",
       "551470  ...  0.035  0.035  0.032  0.032  0.032  0.032  0.031  0.031  0.029   \n",
       "551471  ...  0.049  0.047  0.046  0.043  0.043  0.050  0.051  0.056  0.049   \n",
       "\n",
       "           29  \n",
       "0       0.016  \n",
       "1       0.010  \n",
       "2       0.001  \n",
       "3       0.005  \n",
       "4       0.027  \n",
       "...       ...  \n",
       "551467  0.047  \n",
       "551468  0.047  \n",
       "551469  0.044  \n",
       "551470  0.027  \n",
       "551471  0.049  \n",
       "\n",
       "[551472 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('./LSTM1.csv.gz',header=None)\n",
    "display(df1)\n",
    "df2 = pd.read_csv('./LSTM2.csv.gz',header=None)\n",
    "\n",
    "df3 = pd.read_csv('./LSTM3_1.csv.gz',header=None)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(np.round( (df1.values+df2.values+df3.values)/3, decimals=4))\n",
    "df.to_csv(f'./LSTM_1+2+3.csv.gz',index=False,header=False,compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3c631a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_L' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fe068dddd352>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./LSTM1.csv.gz'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mskus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msku\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_L\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_L' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('./LSTM1.csv.gz',header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04f190a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-347d70b127ae>:107: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efc92a42dc0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAExCAYAAABYlSckAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAx3klEQVR4nO3dd5gUVdbH8e8BCQooKogBFBVzYoU1u44iAiLmnBZdRQyoixjXVdeEuuaEoihiwgiiYsAwhjVjQMVXxYyyC6gkCTLDef+4NdoOE3qmQ3V3/T7P0890d92pPqerw+lbt26ZuyMiIiIijdMk7gBEREREipmKKREREZEMqJgSERERyYCKKREREZEMqJgSERERyYCKKREREZEMqJgSKQFm9rWZ7Rp3HNJ4ZuZm1iXuOESk4VRMieSQme1gZq+Z2Wwz+8nM/mNmf46W9TezVwsgxovM7EMzqzCzC6otW83MxpnZD9GXfecGrvtrM1tgZnPNbFb0XAw0s7x+9phZuZkdk4P1XmBm92R7vdnS0PjMrIWZjTCzb6Jt9r6Z9anW5kAz+yRaPtnM9s564CJFRsWUSI6Y2fLAE8ANwErAGsC/gEVxxlWDKcAZwJM1LFsCPA3sl8H6+7l7G2At4DLgTGBEBuuT3FkG+A7YCVgBOBd4sKqINrM1gHuAwcDywOnAfWa2SizRihQKd9dFF11ycAG6A7NqWbYRsBCoBOZVtSN8gY0CZgDfEL7MmqT837HAJ8BcYDKwZXT/18CuKev+CjikgfHeA1xQy7JlAAc6V7v/LOCJOtb5W1wp921FKNI2jW73Bd4D5hC+yC9IafskMKja/08C9gEMuAaYHv3vh1XrrNb+kuh5Xhg91zdG928HvA3Mjv5uV0ceZwLfR8/7p0APoDfwK7A4Wu8HUdvVgXHAT4RC9diU9TQFzgG+iNY1EegULXOgS3R9h+i5KCP86D03ej1Mj14fK0TtyoCpNT3ntcXXiNfxJGC/6PrWwPRqy2cA28b9ftNFlzgvsQegiy6leiH8cv8RuAvoA6xYbXl/4NVq940CHgPaAJ2Bz4C/RcsOiL7Q/xwVEl2AtaJlVV+gWwLfAnukrPNm4OY04m1wMZXGOr+mWjEV3f8tcHx0vQzYLCoaNgf+B+wdLTsQeDPl/7aIntPmQK+oGGkbPR8bAavVEkc5cEzK7ZWAn4EjotwOiW6vXMP/bhAVNqtHtzsD60bXLwDuqdb+5eg5bwl0jYqNXaJlpxOKvg2imLeoeszo+e0SFUHfAVtF9x9NKMrWAVoDjwJ3pzx3NRZTdcRXZwFcrW0HQhG6YXS7KfASsGd0fW9gKtAq7vebLrrEedFuPpEccfc5hB4GB24DZkTjjzrU1N7MmgIHA2e7+1x3/xq4ivCFD3AMcIW7v+3BFHf/JmUVOxJ6RI509ydS4jjB3U/Idn4Z+oFQ0ODu5e7+obsvcfdJwP2E3UwQ8lnfzNaLbh8BPODuVT0ubYANAXP3T9x9WpqP3xf43N3vdvcKd78f+D+gXw1tK4EWwMZm1szdv3b3L2paqZl1ArYHznT3he7+PnA7cGTU5BjgXHf/NNqGH7j7jymrOAC4Fejj7m9F9x0GXO3uX7r7POBs4GAzWybNXP/A3S9z9z3qa2dmzYB7gbvc/f+i/60kFPz3EXZX3wcc5+6/NCYWkVKhYkokh6Iv+P7u3hHYlLAL6NpamrcDmhF251T5hjDWCqATYfdQbQYCr7l7eSYx58kahN1gmNnWZvaimc0ws9mEPNoBuPtC4AHg8GjQ+iHA3dGyF4AbgZuA6WY2PBqnlo7V+ePzDH98rn/j7lOAUwm9PNPNbLSZrV7Hen9y97m1rLe+bXgq8KC7f1RHrN8QetNqLMqzIXqu7ybsJjwp5f5dgSsIPWLNCUXv7WbWNVexiBQDFVMieRL9uh9JKKog9FilmknobVkr5b41Cbv2IOz6WbeOhxgIrGlm12QcbA5FRzOuAVQdyXgfoQeqk7uvANxC2AVW5S5C70wPYL67v161wN2vd/duwMbA+oTdaDWp/lz/wB+fZ/jjc/3Hf3a/z913iP7HgcvrWO9KZtamlvXWtw0PAPY2s1PqiHVNoIKwO/QXYLmqBVHvZvvU0Ot4rBqZmREOEOhAGCu1OGVxV+Bld38n6kl8G3iTsItZJLFUTInkiJltaGanmVnH6HYnQs/KG1GT/wEdzaw5/LYL5UHgEjNrY2ZrEY6aqjq0/XZgiJl1s6BL1KbKXMJ4m7+Y2WUNiLOZmbUkfB4sY2Ytoy/lquUtCbu5AFpEt6uWXWBm5Wk+zvJmtgcwmjCO58NoURtCb85CM9sKODT1/6LiaQlhl+fdKev7c9Sr1YxQVCyM2tXkf4QxR1XGE3YfHmpmy5jZQYSC7Inq/2hmG5jZLmbWInqMBSmP8z+gc9VUD+7+HfAaMDR6HjcH/sYft+FFZrZetA03N7OVUx7uB0LReIqZHR/ddz/wdzNb28xaA5cSdnVWEMbUtTSzvtHzcC6/b6ul4kvTMML4s37uvqDasreBHat6oszsT4Tdy5MasH6R0hP3oC1ddCnVC6H35UFCr8Qv0d9bgeWj5c0JR6v9BMyM7luR8MU7g9CLcR5/PJpvIOFosnnAR8Cfovu/5vdBxysBHwAXRbdvAW6pI86RhB6M1Ev/lOXVl3nKshHAJXWs+2tC8TGXcNTc68CJQNOUNvsTdl3NJRQzN7L0oOlzo8deJ+W+HoQv8XmEXr17gda1xLEtofD4Gbg+um8HwgD22dHfHWr5382Bt6L4fopirBqMvjKhh+1n4N3ovo5Rm58Iu/QGpqyraZTLV9H63gY6pjzPVUfzrR09J8cQitzzotfDjOj1sWLKOvsD0whH+g2p9lqoKb5zgKdqybWq563qyMeqy2EpbU4iDIifC3wJnBb3e00XXeK+mHuDe4FFRAAws/eBHv7HQdS5eJwjgQEedrWJiBSURh0NIiIC4O5dc/0YZrYccAJhugERkYKjMVMiUrDMrBdh19b/CAPVRUQKjnbziYiIiGRAPVMiIiIiGVAxJSIiIpKB2Aagt2vXzjt37hzXw//ml19+oVWrVnGHkXdJzFs5L+3LGeEsIOu0L53nRds5OZKYd6Y5F+N7vlC288SJE2e6e/ualsVWTHXu3Jl33nknrof/TXl5OWVlZXGHkXdJzFs5L+2gW8Nk4g8ct22eIso9befkSGLemeZcjO/5QtnOZlb9FFS/0W4+ERERkQyomBIRERHJgIopERERkQyomBIRERHJgIopERERkQyomBIRERHJgIopERERkQyomBIRERHJQGyTdoqIiIjU6Zpr2PK222D55etut+++cMYZ+YmpBiqmREREpPBcdRUMGYKttx60bVt32+WWy0tItVExJSIiIoVl+HAYMgQOOICJxx1HWY8ecUdUJ42ZEhERkcJx//0wcCD06QP33ANNm8YdUb1UTImIiEhhePxxOPJI2HFHePhhaN487ojSomJKRERE4vfCC3DAAdC1ayiqYh4H1RAqpkRERCReb7wBe+4JXbrA00/Xf/RegVExJSIiIvGZNCmMj+rQASZMgJVXjjuiBlMxJSIiIvH47DPYbTdo1Qqeew5WWy3uiBpFUyOIiIgkxa+/wrRp8M/xcUcSjBoFlZVQXg5rrx13NI2mYkpERCQJZsyADz6A+fPhgUvjjiZYdVV45hnYcMO4I8mIiikREZFSN2sW9OoFGx8cjpa7rzLuiEqKxkyJiIiUsl9+gb594aOPYJNNYIUV4o6o5KhnSkREpFQtWgT77BOmHnjgAfhxpbgjKknqmRIRESlFFRVwyCFhuoERI2D//eOOqGSpmBIRESk1S5bA0UfDmDFw3XXQv3/cEZU0FVMiIiKlxB0GDYK774aLLoKTT447opKnYkpERKSU/OMfcPPNMGRIuC45pwHoIiIiubRkCbzzThgMnqEVJk2Cpk1rbzBhAgwdCgMGwBVXgFnGjyn1UzElIiKSK0uWwBFHwH33ZWV1f0qn0aGHhp4pFVJ5o2JKREQkF9zhxBNDIXX22dCjR8arfP/99+natWvtDVq2hG22qbv3SrJOxZSIiEi2ucOZZ8Itt4S/l2bn9C2zmjaFsrKsrEuyRwPQRUREsu3SS+Hf/4bjjw9jmKSkqZgSERHJphtugHPPhcMPhxtv1NilBFAxJSIiki133RXmddprL7jzTmiir9kkqHcrm1knM3vRzCab2cdmdkoNbczMrjezKWY2ycy2zE24IiIiBeqRR8Ks47vuCqNHwzIalpwU6WzpCuA0d3/XzNoAE81sgrtPTmnTB1gvumwNDIv+ioiIlL5nngnnwdt6axg7NhxVJ4lRb8+Uu09z93ej63OBT4A1qjXbCxjlwRtAWzNbLevRioiIFJpXXoF99oGNN4bx46FVq7gjkjxrUB+kmXUmzBn2ZrVFawDfpdyeGt03LZPgREREcmLJEjjpJBg5MkxjkIlFi2D99eHZZ6Ft22xEJ0XGPM0XkZm1Bl4CLnH3R6stewK4zN1fjW4/D5zp7u9UazcAGADQoUOHbqNHj848gwzNmzeP1q1bxx1G3iUxb+W8tKFvLgDg7K2XzVdIOaftnByNztudLjfcQMcxY/jfLruwaJVVMopjSbNm/NCvH7+2b5/RetKR6bYuxvd8oby+d95554nu3r2mZWn1TJlZM+AR4N7qhVTke6BTyu2O0X1/4O7DgeEA3bt397ICmHisvLycQogj35KYt3Je2rBPXwegrGzbPEWUe9rOydHovM89F8aMgcGD6XDllVmZuqBzxmtIT6bbuhjf88Xw+k7naD4DRgCfuPvVtTQbBxwZHdW3DTDb3bWLT0RECssVV8All8Axx0CWCimRdHqmtgeOAD40s/ej+84B1gRw91uA8cDuwBRgPnBU1iMVERHJRNWpXQ46KFxXISVZUm8xFY2DqvMV52Hg1YnZCkpERCSr7rsPTjgB+vaFu+/WiYAlqzQ1q4iIlLbHHoMjj4SddoKHHoJmzeKOSEqMiikRESldzz8PBx4I3brBuHGwbPEcxSbFQ8WUiIiUptdfD+fIW399eOopaNMm7oikRKmYEhGR0vPBB7D77rDaamEyzZVWijsiKWEqpkREpLR89hnsthu0bg3PPRcKKpEcUjElIiKl45tvYNddwylinnsO1lor7ogkARp0bj4REZGC9d//hkJqzhwoL4cNNog7IkkIFVMiIlL8fvoJevaEadNgwgTo2jXuiCRBVEyJiEhxmzsX+vQJY6WefBK2LZ7zzklpUDElIiLFa8EC2HNPmDgRHnkk7OYTyTMVUyIiUpSsogIOOABeeimcImavveIOSRJKxZSIiBSfyko2uvRSePHFcNLiww6LOyJJME2NICIixcUdjj+eVV58Ea64Ao47Lu6IJOFUTImISPFwhyFD4Lbb+Obww+H00+OOSES7+UREpIhcdBFcfTUMGsRX++yDpuSUQqCeKRERKQ7XXgvnnw/9+4frZjEHJBKomBIRkcI3YgT8/e+w335w223QRF9fUjj0ahQRkcL24INw7LHQqxfcey8soxEqUlhUTImISOEaPz5Me7D99vDoo9CiRdwRiSxFxZSIiBSml14Ku/U23xyeeAKWWy7uiERqpGJKREQKz9tvwx57wNprwzPPwAorxB2RSK1UTImISGH56CPo3Rvat4cJE6Bdu7gjEqmTiikRESkcU6ZAz57QsiU89xyssUbcEYnUS4dEiIhIYZg6FXbdFRYvhpdfhnXWiTsikbSomBIRkfhNnx4KqZ9/hhdegI03jjsikbSpmBIRkXjNmhXmkPr22zDYvFu3uCMSaRAVUyIiEp9ffoG+feHjj+Hxx2HHHeOOSKTBVEyJiEg8Fi2CffaBN94Is5z36hV3RCKNomJKRETyr6ICDj44TH1w551hck6RIqWpEUREJL+WLIGjj4axY+H666F//7gjEsmIiikREckfdxg0CO6+Gy6+OFwXKXIqpkREJH/OOQduvhlOPz1cFykBKqZERCQ/hg6Fyy6D446Dyy8Hs7gjEskKFVMiIpJ7N90UeqIOPTT0TKmQkhKiYkpERHJr1Cg46STYc08YORKa6KtHSote0SIikjtjxsBRR0GPHvDAA9CsWdwRiWSdiikREcmNCRPCXFJbbRWmQWjZMu6IRHJCxZSIiGTff/4De+8NG20E48dD69ZxRySSMyqmREQku957D3bfHTp2DCcuXnHFuCMSySkVUyIikj2ffAK77QZt28Jzz0GHDnFHJJJzKqZERCQ7vv4aevaEpk1DIdWpU9wRieSFTnQsIiKZ++GHcMTe/Pnw0kuw3npxRySSN/X2TJnZHWY23cw+qmV5mZnNNrP3o8t52Q9TREQK1o8/hl1706fD00/DZpvFHZFIXqXTMzUSuBEYVUebV9x9j6xEJCIixWPOHOjdG6ZMCYXUVlvFHZFI3tXbM+XuLwM/5SEWEREpJvPnQ79+8P778PDDUFYWd0QiscjWAPRtzewDM3vKzDbJ0jpFRKRQ/for7L8/vPIK3HMP7KGdE5Jc5u71NzLrDDzh7pvWsGx5YIm7zzOz3YHr3L3GkYdmNgAYANChQ4duo0ePziT2rJg3bx6tEziZXBLzVs5LG/rmAgDO3nrZfIWUc9rOeVBZycYXXcQqL73Ep6edxrSYCilt64Yrxvd8oWznnXfeeaK7d69xobvXewE6Ax+l2fZroF197bp16+aF4MUXX4w7hFgkMW/lvLQDb3nND7zltfwEkyfazjlWWel+1FHu4H7VVfl73BpoWzdcMb7nC2U7A+94LTVNxrv5zGxVM7Po+laEXYc/ZrpeEREpMO4weDDceSecd164LiL1H81nZvcDZUA7M5sKnA80A3D3W4D9gePNrAJYABwcVXAiIlIsPvsMJk2qu82rr8J118Epp8AFF+QlLJFiUG8x5e6H1LP8RsLUCSIiUoxeeQV69YIFC+pve/TRcPXVEHZIiAiaAV1EJNkmToS+fWHNNcNReS1b1t62efMws7kKKZE/UDElIpJUkyeHHqmVVoIJE3QuPZFG0omORUSS6Msvw0mJmzXTSYlFMqSeKRGRpPn+e9h1V1i4MJyUuEuXuCMSKWoqpkREkmTmzNAjNWMGvPACbLrUXMwi0kAqpkREkmL27DBG6quv4Kmn4M9/jjsikZKgYkpEJAnmzw/nz5s0CR57TCclFskiFVMiIrkyd26YNTzHmv7yC8yZU3uDigo47DB47TW4/37YffecxySSJCqmRESyrbISjjoK7r47Lw+3Y7oNR4yAAw/MZSgiiaRiSkQkm9xh4MBQSJ1wAqy7bs4fcsqUKXSp74i8TTeF3XbLeSwiSaRiSkQkW9zhtNPg9tvh3HPhoovy8rBTy8vpojFQIrHRpJ0iItly4YVwzTUwaFC4LiKJoGJKRCQbrrkGLrgA+veHa6/V+etEEkTFlIhIpkaMgMGDYb/94LbboIk+WkWSRO94EZFMPPAAHHss9O4N994Ly2goqkjSqJgSEWmsJ5+Eww+HHXaARx6BFi3ijkhEYqBiSkSkMcrLYf/9YYst4IknYLnl4o5IRGKiYkpEpKHeegv69YN11oGnn4bll487IhGJkYopEZGG+PDDMD6qfXuYMAHatYs7IhGJmYopEZF0ff459OwJyy4Lzz8Pq68ed0QiUgB02ImISDq++w523TWcd++FF2DtteOOSEQKhIopEZH6TJ8eCqlZs+DFF2HjjeOOSEQKiIopEZG6/PxzOEHwd9/Bs8/CllvGHZGIFBgVUyIitZk3D/r2hcmT4fHHw3xSIiLVqJgSEanJwoWw997w5pvw0EPQq1fcEYlIgVIxJSJS3eLFcPDB4Yi9kSNh333jjkhECpiKKZF0ffkl3HUXLFkSdyRp6/zNN6EgqE1FNJD6n+PzE1Ae1JtzOiZOhKeeghtugL/+NTuBiUjJUjElkq5Bg2D8eGhSPNOzrVVfg4MuCX8fuDTXoeRNvTmno1kzuPxyOOmkbKxNREqciimRdHzwQSikLr4Y/vGPuKNJ20vl5ZSVldXe4NbXw9/7KvMSTz7Um7OISJYVz09skThddhm0aQMnnhh3JCIiUmBUTInU54sv4MEHYeBAaNs27mhERKTAqJgSqc+//x3G0Pz973FHIiIiBUjFlEhdpk2DO++E/v1htdXijkZERAqQiimRulx7LVRUwOmnxx2JiIgUKBVTIrWZNQuGDYMDD4R11407GhERKVAqpkRqc9NNMHcunHVW3JGIiEgBUzElUpP588Muvt13hy22iDsaEREpYCqmRGpyxx0wc6Z6pUREpF4qpkSqW7w4TIew/faw445xRyMiIgVOp5MRqe7+++Hbb+Hmm+OOREREioB6pkRSLVkSTnC72WZhvJSIiEg91DMlkurxx2HyZLj3XjCLOxoRESkC9fZMmdkdZjbdzD6qZbmZ2fVmNsXMJpnZltkPUyQP3GHoUFhnnTC3lIiISBrS2c03Euhdx/I+wHrRZQAwLPOwRGJQXg5vvhlmO19GnbYiIpKeeospd38Z+KmOJnsBozx4A2hrZjqJmRSfyy6DDh3CefhERETSlI2f32sA36XcnhrdNy0L687IqafC++/X3WbWrK60bZuHYApMovJeuBA+nIQvMIyXa2/nZ8Pa60DvlvmLLcfq287TNg5/y8ryEU1+JOq1HUlizpDMvDPNuRjf8+nk3LVrmGc5Lnndl2FmAwi7AunQoQPl5eU5fbypU7swa1brOttUVlYya9asnMZRiJKSd5PFi2k95XOsopKFK69ME6u9M9abNGFR61Z4CT0v9W3niooKgJJ6LSTltZ0qiTlDMvPONOdifM+nk/PUqfMoL5+Sn4BqkI1i6nugU8rtjtF9S3H34cBwgO7du3tZjkvjdFZfXl5OruMoRInI+8cfoWwXaPYVvPQc5Qtnln7O1dS3nQ+6NXwEPDC8bX4CyoNEvLarSWLOkMy8M825GN/z6eXcllB+xCMb80yNA46MjurbBpjt7rHv4pOEmzsX+vSBzz+HceNgm23ijkhEREpUvT1TZnY/UAa0M7OpwPlAMwB3vwUYD+wOTAHmA0flKliRtCxYAP36wXvvwaOPwi67xB2RiIiUsHqLKXc/pJ7lDpyYtYhEMvHrr7D//vDyy2HizX794o5IRERKnCbTkdJRWQlHHAHjx8Ott8Ihdf4OEBERyQqdm09Kgzscdxw8+CD8+98wYEDcEYmISEKomJLi5w6DB8OIEXDuuTBkSNwRiYhIgmg3nzTO8OHw5JNxRxHMmRNOBXPyyXDhhXFHIyIiCaNiShru+uvhlFNg3XWhTZu4ownOOCOcpNgs7khERCRhVExJw4wcGQqpffYJ45N0QmAREUk4jZmS9D38MPztb9CzJ9x/vwopERERVExJup5+Gg49FLbdFsaMgRYt4o5IRESkIKiYkvq98grsuy9suik88QS0ahV3RCIiIgVDxZTU7Z13oG9fWGsteOYZaNs27ohEREQKioopqd3kydC7N6y8MkyYAO3bxx2RiIhIwVExJTX78kvYdVdo3hyeew46dow7IhERkYKkw7GSprIS7r6b1d97Dz7+uOY27nD11bBoUThh8Lrr5jdGERGRIqJiKmlGjYKjj2b9+tqtuCI8+yxsskk+ohIRESlaKqaSpLISLr8cunblP+edx/Y77FB72zZtoGXL/MUmIiJSpFRMJcljj8Gnn8Lo0SxecUUNKBcREckCDUBPCvdw7rouXWD//eOORkREpGSoZyopnn8+zBk1fDg0bRp3NCIiIiVDPVNJMXQorLYaHHlk3JGIiIiUFBVTSfDWW/DCCzB4sM6pJyIikmUqppLgssvCVAfHHRd3JCIiIiVHxVSp++QTGDMGTjopTHcgIiIiWaViqtRdfjksuywMGhR3JCIiIiVJxVQp+/ZbuPdeOPZYzSklIiKSIyqmStlVV4W/p50WbxwiIiIlTMVUqZoxA267DQ4/HNZcM+5oRERESpaKqVJ1/fWwcCGccUbckYiIiJQ0FVOlaO5cuPFG2Htv2GijuKMREREpaSqmStGtt8KsWXDWWXFHIiIiUvJUTJWaRYvg6qthl11gq63ijkZERKTk6UTHpeauu2DaNBg1Ku5IREREEkE9U6XEHa68Erp3hx494o5GREQkEdQzVUrefRc+/xzuuAPM4o5GREQkEdQzVUrGjoUmTaBfv7gjERERSQwVU6VkzBj4y1+gXbu4IxEREUkMFVOl4vPP4eOPw9xSIiIikjcqpkrF2LHhr4opERGRvFIxVSrGjoU//QnWWivuSERERBJFxVQp+O9/4fXXYZ994o5EREQkcVRMlYJx48IcU9rFJyIikncqpkrBmDGw7rqw6aZxRyIiIpI4KqaK3Zw58PzzoVdKE3WKiIjkXVrFlJn1NrNPzWyKmZ1Vw/L+ZjbDzN6PLsdkP1Sp0fjxsHixxkuJiIjEpN7TyZhZU+AmoCcwFXjbzMa5++RqTR9w95NyEKPUZexYWGUV2GabuCMRERFJpHR6prYCprj7l+7+KzAa2Cu3YUlaFi0KPVN77QVNm8YdjYiISCKlU0ytAXyXcntqdF91+5nZJDN72Mw6ZSU6qdsLL8DcuTqKT0REJEbm7nU3MNsf6O3ux0S3jwC2Tt2lZ2YrA/PcfZGZHQcc5O671LCuAcAAgA4dOnQbPXp09jJppHnz5tG6deu4w2iU9a+8klVeeIH/jB2LN2/eoP8t5rwbSzkvbeibCwA4e+tl8xVSzmk7J0cS884052J8zxfKdt55550nunv3mpbVO2YK+B5I7WnqGN33G3f/MeXm7cAVNa3I3YcDwwG6d+/uZWVlaTx8bpWXl1MIcTRYZSUcdBD068dOu+3W4H8v2rwzoJyXNuzT1wEoK9s2TxHlnrZzciQx70xzLsb3fDFs53R2870NrGdma5tZc+BgYFxqAzNbLeXmnsAn2QtRavTGGzB9uo7iExERiVm9PVPuXmFmJwHPAE2BO9z9YzO7EHjH3ccBJ5vZnkAF8BPQP4cxC4Sj+Jo1gz594o5EREQk0dLZzYe7jwfGV7vvvJTrZwNnZzc0qZV7mPW8Rw9YYYW4oxEREUk0zYBejD7+GL74QkfxiYiIFAAVU8VozJhw6pi9NN2XiIhI3FRMFaOxY8OM56uuGnckIiIiiadiqth88w28+66O4hMRESkQKqaKzWOPhb8aLyUiIlIQVEwVmzFjYJNNYL314o5EREREUDFVXH78EV5+Wbv4RERECkha80xJnsybB0uW1L78kUfCcu3iExERKRgqpgrFzTfDiSfW365TJ9hyy9zHIyIiImlRMVUIFi2CSy4JRdJhh9XddrvtwhxTIiIiUhBUTBWCe+6BH36AO++E3XaLOxoRERFpAA1Aj1tlJVx+eeiV6tkz7mhERESkgdQzFbdHH4XPP4eHHtLuOxERkSKknqk4ucPQobD++pruQEREpEipZypOEybAe+/B7bdD06ZxRyMiIiKNoJ6pOA0dCmusAUccEXckIiIi0kjqmYrLG29AeTlcfTU0bx53NCIiItJI6pmKy9ChsNJKcOyxcUciIiIiGVAxFYePP4Zx42DQIGjdOu5oREREJAMqpuJw+eXQqlUopkRERKSoqZjKt6+/hvvugwEDYOWV445GREREMqRiKt+uvBKaNIHBg+OORERERLJAxVQ+TZ8OI0aEqRA6dow7GhEREckCFVP5dN11sGgRnHFG3JGIiIhIlqiYypc5c+Cmm2C//WCDDeKORkRERLJExVS+DBsGs2fDWWfFHYmIiIhkUbJnQP/uO9a66y54/vncP9bw4dCzJ3TrlvvHEhERkbxJbjH1/few006s/dVX4ei6XGvRAs4/P/ePIyIiInmVzGJq5szQSzRzJhOHDaPbwIFxRyQiIiJFKnnF1OzZ0KsXfPUVPPMMc5csiTsiERERKWLJGoA+fz7ssQd8+CE8+ij85S9xRyQiIiJFLjk9U4sWwb77wmuvwejR0KdP3BGJiIhICUhGMVVRAYcdBs88E2YgP+CAuCMSERGRElH6u/mWLIFjjoFHHoFrroGjj447IhERESkhpV1MucOpp8Jdd8G//hWui4iIiGRRaRdT//wn3HADDB4crouIiIhkWekWU+XlcMklYRfflVeCWdwRiYiISAkq3QHoO+0UxknttZcKKREREcmZ0i2mzMJUCCIiIiI5VLq7+URERETyQMWUiIiISAZUTImIiIhkIK1iysx6m9mnZjbFzM6qYXkLM3sgWv6mmXXOeqQiIiIiBajeYsrMmgI3AX2AjYFDzGzjas3+Bvzs7l2Aa4DLsx2oiIiISCFKp2dqK2CKu3/p7r8Co4G9qrXZC7gruv4w0MNM8xGIiIhI6UunmFoD+C7l9tTovhrbuHsFMBtYORsBioiIiBSyvM4zZWYDgAEAHTp0oLy8PJ8PX6N58+YVRBz5lsS8lfPSZs1aAFBSz4u2c3IkMe9Mcy7G93wxbOd0iqnvgU4ptztG99XUZqqZLQOsAPxYfUXuPhwYDtC9e3cvKytrRMjZVV5eTiHEkW9JzFs5L23Yp68DUFa2bZ4iyj1t5+RIYt6Z5lyM7/li2M7m7nU3CMXRZ0APQtH0NnCou3+c0uZEYDN3H2hmBwP7uvuB9ax3BvBNHU1WIOwurEs22rQDZubhcdJpk6/Hgfrzzmcs+XpesrGtlXO8bfKVc7Zi0edYbtvocyzeWJL2nl7L3dvXuMTd670AuxMKqi+Af0T3XQjsGV1vCTwETAHeAtZJZ731PObwfLQB3imgWPLyOOnknedY8vW8ZLytlXNRPC95eU8X2POiz7H4Y9F7OnexFMx7urZLWmOm3H08ML7afeelXF8IHJDOuhrg8Ty2ydfj1NcmiTmn0yZfOaezHuUcb5t85ZxOm0J6XtJRSNuo1HJOp43e041fRzpijaXe3XylzszecffucceRb0nMWzkng3JOjiTmrZwLk04nEw2IT6Ak5q2ck0E5J0cS81bOBSjxPVMiIiIimVDPlIiIiEgGVExJyTCztnHHICLZY2Zt4o5BJB0lX0yZ2QlmtqOZrRbdTkLOp5rZ9mbWIbqdhJzPB16t4STcJc3Mzjazw8xs0+h207hjyjUz+6uZbWpmy0e3S/48oGZ2rJltYmato9tJyPkC4FEzWzfuWPLJzAabWR8zWzu6nYTP74FmtkVV8VyMr++S3UhmtoeZfQD0BA4Cbgdw9yWxBpZD0YvxLWBrYHvgfijtnAHM7GJgY2Bvd58cdzz5EH3Yvg9sCqwKTABw98o448olM9snek/vB5wBXAzgJTzw08y2inLuBRwMXAsln/MyZnYDsCFwvLt/EXdM+WBm/czsXWCb6DIKSvvzO/qB8B6wB3A8cD0U5+u7JIspM2sP7AgMdvd9gHOBuWbWN97Icm5d4Bl3P8TdrwCam9ktUJyVfjrMbFlC4XiUu08xs45VPRalKvr11h442d0Pc/erCL1yq0bLS25bm1lHYE9gkLvvSSgqWpnZlrEGlntbALe5+/7Av4C1zexfUFo9FtVes62BLdz94Og9vYqZNauhXckws3bABsApHs4ecjPweQJ6ItsDb7j7HsBpwMpmdgUU3+u7qIKti5mtZGZHmtlK7j6D0BP1UrS4EnDqPn1N0YlyPsLMVozu2gxYLqXJU8C+Zraeu3spvCHNbPnoFEeYWRN3X0CYnX83M7seuA94yMx6mFmLOGPNJjNb0cwOMLMV3X2uu49y95fNrJWZPUbY9kea2SrF+KuuJlHOu5vZcu4+FbgKeDVa/D3QGfhfXPHlQkrOy0Z3bU84HyruXgH8H3CKma3q7ktK5D3dpuo1G32B/gpMNrOtzexW4F7Ce3qzUnltQxjjGX1OLevuM4Gr3f0VM1sOGAFsDvSL3vOl8vm9opnta7+PhesCLAZw91+Ak4FjzWyNYnt9l0QxZWYHAu8B+wJXmtnx7v65u1dEG+MXYBWglL5cq3LeD7jGzA4DbgJ2NrMzzeyfwJpAOXAJFGfXaSozGwTMAs6D0P0d/XKbCewMLHT3vxBmsT0IWC+mULPKzIYArwFHADdG27rKtsB/CLuBVgZKoifSzP4KfAScANxsZr3d/aNom1d94VYALYo91yrVch5uZlsD/wT+ZmFc3JnAXMKPpHOhJN7TQ4DZ0d+qXVrLAm2AfYAZ7t4TmAScaSUyIN3MTgfeBP4O3G5m26UUD/sBbwAnEorpUfFFmj1mNpjwY+hwwudYV8LwhAPMbCUAd/8aGEkRfmeVRDEFrAOc5e57EzbEgWbWB37bGBsB7d19Ivx+hEiRfwin5nwHcBzhl/qBwBxCIXURMASYX9VdXKwsDEJdhfBFs5+ZdQJw93mED6Xu/P4L50bCNl89nmizx8zKgDJgp2j31ivAxinbs9zdr3D3b9z9TGAHM9uomD6EarEZcGDU/f8S8Fcz2x5++8LdFGjj7l9Gv9qXg6J/T6fm/ALhvbsM4UdiJ0JPxc3AbcBPVT20xcrMtiB8jg0kFErLAbj7j4T8dwe+je47jzAWtOgPMDGzPYFdgR2jbf0D0A1++756wN0vdvc3Ca+Bjcxs7WJ+T0c5bwf0dvd9gVZAF3f/Bnia6EdgZBTQ1MxWyH+kjVcqxdQ2VVfc/WXgLuAfKctXJRwVsnq0S+TvUduifXGydM4jCd3EU9x9mLsfG+0a2R34Mio6ilY0CPVOd7+F0BNzYcriJwjnjmxtZt2jQmM29Z9BvOC5eznwT3efHt31PbBl1faMdv0AEP3Sey5qU+x2IpzBHeAxwi/1gSnL1wQejMbTjAb+CkX/nq6e82vA+e7+irtfFo2P+xbYCvg5ddsXI3f/ALjW3YcTetCHpSy+i/AjqZ2ZdY6GMnxM6IUudhOAU1Pe05MJB0oB4O6/prTdDngZ+C5/4WWfu49z9/3d/TszW4+w63odM2sODAC2NLOq8/t2AWa5e1F9fhd1MZUyQO1RwtE9Ve4HZpjZ4dHtLQm7hsYRBminfhEXlTpyvhf40cwOjdqtYWbDCfug38lvlDnzVfR3CLCjme0Av/VUDCcUWWcDrwPPR7/sip67v5d6E/jezJpa0NzMNjCzawnjLMrdfU4sgWaB/T61wx3AsQDu/hPh12ulmfWKlm9GGJD9FPCKuw+rvq5iUUfO48Ni6xm162ThgJIjKZ339OfR32OBvc1sc/jtR8JVwE/AdYSCotxL4Mg+d1/g7p+k3NUSeB/CxjazZma2kZldDfwbeLnYC+cqFg4Ou53wA3hN4BpgfeBvQA8zm0DYo1J0n91FU0xZmOpgE0s5qqNq/IS7jyIUElW/XI3wS7bqV96ahBflTu5+c96Db6RG5lw1GL0T8CWwtbuPz3vwjVRTzlV/o905zaJi4Vb+2Dv1s7s/CJwK/Nndr8l37JmoK+/ob7Oo6ZaEXCs9+JWwy2s24fVd8OewqmJmB1o49P+33e7uXhnlPB6osDA2EMKX6hx+/8zamFB87OjuN+U79sZqRM6zCbv6IOzKnkZ4T7+S79gbq6acq/6mvKdnEY7QvDXlXz+LeqLPAbZy92vzG3lm6so7+ts8aroh8COEnlV3XwzsQhgXuJO7j8x37I1VV87R9p4B7ObuFwPnA/OAMnd/CRgEXAl0d/d7Ykqh0Qr+3HwWxoxcTvhQWUgoGK5z91/MbJmqit3CeIpHgW7uPtXMbgTec/cRZtbS3RfGk0HDZZjzRHe/Myq4imZ+knRzrvY/rwIfAGsDN7j7U/mLODsamne0jUcAzQkfPlcB7xfT7i0z24nw63MhYffFdOBCd19Q7fVdNa1JmbvPNbP7gUfc/WELR/jNjyuHhsow5wfdfYyZNfUimkesnpxrzMXMPif0WqwMDHP31/MZczY0NO9oG59FGON5GOGH/9RS39bR/90BPOXuD+Uv2two2J4pC7sxWhJ2U13j7rsBNwCrEQZa4+Fovc4W5qV4k7Cr50Ize5kwWPG9qF1RFFJZyvmDqF1RFFINzHmo/T4r8DKEOUp6ASOLrZBqRN7rRr1TfwLuJOz6eNDd3yuWQirKeVnCbqrro5wfIRy5VQF/yPk0wiDkt4Bbzew5wvPyYdSuKAqpLOU8OWpXFF+uaeZcWZWzma0e/V8zYAmwF/BEsRVSjcnbwlkquhAGXV8HPOvhYJJS39bdzGwkYW7ESfFEn2XuXlAXQpf2lcCNwJ+BzVOWLQe8C6wf3e4NfAKcFt1uShhsvn/ceSjnnOR8anS7CWGMxVlx55HnvFsBPxMm9os9l0bmvB3QImXZHYRB892AtoSjnGYCJ6b874bAkXHnoZyznvMMYGC0vClwAfCPuPPIU97HR8vXJEx3cXLceeRxW3ckjIE7M+48snkpqN180f7Vm4DlCQNOjyAMGr/Z3d3CiWxHAUPc/TMLh9K2cPefo/8vql1boJxpRM7ROpKa97IeJiotCtVyfgroD4wl9KieSBhI/gawCWEXwTlAWw8DsH8bV5P3wDOgnBuec7SOGnfnF7Is5V1su6yzkXNRDb1JR6HNU9IG6Ar08jBeYAbh0P4jCYfKdgZWcvfPovbm7j9H3cMVxfblGlHODc/ZE5x30RRSkeo5zwT6AXt4yoBiM+tGGCvU2d2/tHCE25JiKyoiyrkRORdbIRXJRt5FU0hFspFzSRVSUGBjpjwcpfU1odKFcKj7e8DWFo4OWAd41syamNkwwpcQ7r64SD+AlHNQ8jlDMvOuJed3gJ4WnUsw0h74yd2/jP6vUjkXjyTmDMnMO4k5p6OgiqnIGKCrma3mYWLCSYSZrdcmzEdxAvA24TQDRTu3TDXKORk5QzLzrinnhcBq0cDUcwhHML0JRT+LeRXlnIycIZl5JzHnOhViMfUqYTBmfwB3f5cwv0olYT6diUBfD6cXKBXKORk5QzLzrinnraJlhwBbALt7NEdWifx6Vc7JyBmSmXcSc65ToY2Zwt2nWTjly2VmNoXwK72CcMhs/yLdr14n5ZyMnCGZedeS82JC3ld4kRwG3hDKORk5QzLzTmLO9Smoo/lSWThR8QGEwy5v9HDy2pKmnJORMyQzb+WsnEtZEvNOYs61KdhiCn6bxM1L8dd6bZRzciQxb+WcDEnMGZKZdxJzrklBF1MiIiIiha4QB6CLiIiIFA0VUyIiIiIZUDElIiIikgEVUyIiIiIZUDElIiIikgEVUyIiIiIZUDElIiIikgEVUyIiIiIZ+H/v57CV5QDB3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def savitzky_golay(y, window_size, order, deriv=0, rate=1):\n",
    "    import numpy as np\n",
    "    from math import factorial\n",
    "    \n",
    "    try:\n",
    "        window_size = np.abs(np.int(window_size))\n",
    "        order = np.abs(np.int(order))\n",
    "    except ValueError:\n",
    "        raise ValueError(\"window_size and order have to be of type int\")\n",
    "    if window_size % 2 != 1 or window_size < 1:\n",
    "        raise TypeError(\"window_size size must be a positive odd number\")\n",
    "    if window_size < order + 2:\n",
    "        raise TypeError(\"window_size is too small for the polynomials order\")\n",
    "    order_range = range(order+1)\n",
    "    half_window = (window_size -1) // 2\n",
    "    # precompute coefficients\n",
    "    b = np.mat([[k**i for i in order_range] for k in range(-half_window, half_window+1)])\n",
    "    m = np.linalg.pinv(b).A[deriv] * rate**deriv * factorial(deriv)\n",
    "    # pad the signal at the extremes with\n",
    "    # values taken from the signal itself\n",
    "    firstvals = y[0] - np.abs( y[1:half_window+1][::-1] - y[0] )\n",
    "    lastvals = y[-1] + np.abs(y[-half_window-1:-1][::-1] - y[-1])\n",
    "    y = np.concatenate((firstvals, y, lastvals))\n",
    "    return np.convolve( m[::-1], y, mode='valid')\n",
    "\n",
    "skus = pd.read_csv('./dataset/test_data.csv')\n",
    "\n",
    "skus = skus['sku']\n",
    "\n",
    "sku = skus[2256]\n",
    "\n",
    "df2 = pd.read_csv('./preds/Lightgbm_3_test.csv',header=None)\n",
    "def sep_train_val(df,validation_mode=0):\n",
    "    train_init = pd.to_datetime('2021-02-01T00:00:00.000000000')\n",
    "    val_init = pd.to_datetime('2021-02-25T00:00:00.000000000')\n",
    "\n",
    "    is_train =  (pd.to_datetime(df['date']) - train_init).dt.days < 24\n",
    "    is_val = ~is_train & (( pd.to_datetime(df['date']) - val_init ).dt.days < 30)\n",
    "    train = df[is_train].copy()\n",
    "    val = df[is_val].copy()\n",
    "    val['days_passed'] =  (pd.to_datetime(df['date']) - val_init).dt.days\n",
    "    val['cumsum'] = val['sold_quantity'].cumsum()\n",
    "    #print(df)\n",
    "    #print(train.shape,val.shape,val['cumsum'].values[0],val['cumsum'].values[-1])\n",
    "    if (train.shape[0]==0) or (not val.shape[0] == 30) or (val['cumsum'].values[0] ==val['cumsum'].values[-1]):\n",
    "        \"\"\"\n",
    "            Useless sample for validation. Return some other (hopefully good sample instead)\n",
    "        \"\"\"\n",
    "        raise \"\"\n",
    "\n",
    "    if df['stock'].values[0] < 0 or validation_mode == 0:\n",
    "        \"\"\" We take the last day with nonzero sold quantity.\n",
    "            Then, the stock is the amount of items sold from the \n",
    "            beginning of the validation month till this day.\n",
    "        \"\"\"\n",
    "        days_to_stockout = int(val[val['sold_quantity']>0]\\\n",
    "                            ['days_passed'].values[-1])\n",
    "        stock = (val['cumsum'].values[-1] - val['cumsum'].values[0])\n",
    "    elif validation_mode == 1:\n",
    "        \"\"\" The stock is the same as given in the test data. If our\n",
    "            task in the test data is to predict how long till x units of\n",
    "            product y are sold, then we count how many days in the validation\n",
    "            month it took to produce that amount.\n",
    "        \"\"\"\n",
    "        stock = df['stock'].values[0]\n",
    "        if val[val['cumsum']>=stock].shape[0] == 0:\n",
    "            days_to_stockout=-1\n",
    "        else:\n",
    "            days_to_stockout = int(val[val['cumsum']>=stock]\\\n",
    "                                ['days_passed'].values[0])\n",
    "    \n",
    "    \n",
    "    return train, val, stock, days_to_stockout\n",
    "\n",
    "df_sku = df[df['sku']==sku]\n",
    "df_sku_train, df_sku_val,stock, days_to_stockout = sep_train_val(df_sku)\n",
    "\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "# Major ticks every 6 months.\n",
    "fmt_half_year = mdates.DayLocator(interval=7)\n",
    "ax.xaxis.set_major_locator(fmt_half_year)\n",
    "\n",
    "# Minor ticks every month.\n",
    "fmt_month = mdates.DayLocator(interval=1)\n",
    "ax.xaxis.set_minor_locator(fmt_month)\n",
    "\n",
    "# Text in the x axis will be displayed in 'YYYY-mm' format.\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))\n",
    "\n",
    "# Format the coords message box, i.e. the numbers displayed as the cursor moves\n",
    "# across the axes within the interactive GUI.\n",
    "ax.grid(True)\n",
    "fig.autofmt_xdate()\n",
    "#ax.grid()\n",
    "ax.plot(df_sku['date'],df_sku['sold_quantity'].cumsum()/stock,c='red')\n",
    "\n",
    "ax.plot(df_sku['date'],df_sku['minutes_active'],c='blue')\n",
    "ax.axvline(df_sku_train['date'].values[-1])\n",
    "ax.axvline(df_sku_val[df_sku_val['cumsum']>=stock]['date'].values[0])\n",
    "ax.set_title(f\"Stock: {stock}; Days to stockout: {days_to_stockout}\")\n",
    "fig.show()\n",
    "\n",
    "df2['sku'] = skus\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "x = np.arange(30)\n",
    "y = np.round(df2[df2['sku']==sku].values[0,:-1],decimals=3).cumsum()\n",
    "yhat = savitzky_golay(y, 7, 2) # window size 51, polynomial order 3\n",
    "ax.plot(x,y)\n",
    "ax.plot(x,yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0673c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.0595</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.1575</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>0.0935</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.0730</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551467</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.0690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551468</th>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0585</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.0655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551469</th>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0540</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551470</th>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.0340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551471</th>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.0520</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>0.0645</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>551472 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1       2       3       4       5       6       7   \\\n",
       "0       0.0130  0.0125  0.0210  0.0265  0.0390  0.0525  0.0475  0.0595   \n",
       "1       0.0100  0.0130  0.0215  0.0280  0.0430  0.0580  0.0570  0.0665   \n",
       "2       0.1860  0.2390  0.1575  0.1150  0.0965  0.0525  0.0345  0.0185   \n",
       "3       0.0315  0.0360  0.0500  0.0545  0.0850  0.0935  0.0775  0.0730   \n",
       "4       0.0050  0.0065  0.0085  0.0135  0.0205  0.0265  0.0325  0.0380   \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "551467  0.0050  0.0050  0.0065  0.0080  0.0105  0.0115  0.0170  0.0175   \n",
       "551468  0.0055  0.0055  0.0070  0.0085  0.0115  0.0120  0.0175  0.0180   \n",
       "551469  0.0065  0.0075  0.0080  0.0105  0.0135  0.0150  0.0210  0.0210   \n",
       "551470  0.0130  0.0145  0.0170  0.0195  0.0250  0.0290  0.0345  0.0340   \n",
       "551471  0.0045  0.0045  0.0055  0.0075  0.0095  0.0105  0.0160  0.0160   \n",
       "\n",
       "            8       9   ...      20      21      22      23      24      25  \\\n",
       "0       0.0485  0.0480  ...  0.0300  0.0260  0.0230  0.0190  0.0185  0.0195   \n",
       "1       0.0500  0.0540  ...  0.0270  0.0220  0.0200  0.0165  0.0150  0.0170   \n",
       "2       0.0145  0.0130  ...  0.0030  0.0025  0.0015  0.0020  0.0015  0.0010   \n",
       "3       0.0600  0.0435  ...  0.0180  0.0120  0.0120  0.0085  0.0080  0.0090   \n",
       "4       0.0365  0.0350  ...  0.0435  0.0370  0.0345  0.0300  0.0280  0.0340   \n",
       "...        ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "551467  0.0200  0.0240  ...  0.0495  0.0500  0.0435  0.0505  0.0435  0.0525   \n",
       "551468  0.0205  0.0245  ...  0.0495  0.0480  0.0420  0.0500  0.0430  0.0510   \n",
       "551469  0.0225  0.0265  ...  0.0485  0.0480  0.0400  0.0460  0.0415  0.0495   \n",
       "551470  0.0325  0.0375  ...  0.0365  0.0425  0.0330  0.0370  0.0325  0.0385   \n",
       "551471  0.0185  0.0220  ...  0.0505  0.0520  0.0455  0.0515  0.0440  0.0555   \n",
       "\n",
       "            26      27      28      29  \n",
       "0       0.0180  0.0200  0.0155  0.0135  \n",
       "1       0.0150  0.0140  0.0130  0.0115  \n",
       "2       0.0015  0.0010  0.0010  0.0010  \n",
       "3       0.0100  0.0075  0.0080  0.0060  \n",
       "4       0.0320  0.0315  0.0290  0.0250  \n",
       "...        ...     ...     ...     ...  \n",
       "551467  0.0500  0.0605  0.0460  0.0690  \n",
       "551468  0.0500  0.0585  0.0480  0.0655  \n",
       "551469  0.0500  0.0540  0.0485  0.0565  \n",
       "551470  0.0360  0.0350  0.0305  0.0340  \n",
       "551471  0.0510  0.0645  0.0465  0.0760  \n",
       "\n",
       "[551472 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0479</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.0546</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.0603</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>0.0521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.1575</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>0.0935</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.0730</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551467</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.0690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551468</th>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0585</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.0655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551469</th>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0540</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551470</th>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.0340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551471</th>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.0520</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>0.0645</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>551472 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1       2       3       4       5       6       7   \\\n",
       "0       0.0127  0.0153  0.0194  0.0295  0.0385  0.0479  0.0532  0.0533   \n",
       "1       0.0100  0.0144  0.0203  0.0315  0.0425  0.0546  0.0600  0.0603   \n",
       "2       0.1860  0.2390  0.1575  0.1150  0.0965  0.0525  0.0345  0.0185   \n",
       "3       0.0315  0.0360  0.0500  0.0545  0.0850  0.0935  0.0775  0.0730   \n",
       "4       0.0050  0.0065  0.0085  0.0135  0.0205  0.0265  0.0325  0.0380   \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "551467  0.0050  0.0050  0.0065  0.0080  0.0105  0.0115  0.0170  0.0175   \n",
       "551468  0.0055  0.0055  0.0070  0.0085  0.0115  0.0120  0.0175  0.0180   \n",
       "551469  0.0065  0.0075  0.0080  0.0105  0.0135  0.0150  0.0210  0.0210   \n",
       "551470  0.0130  0.0145  0.0170  0.0195  0.0250  0.0290  0.0345  0.0340   \n",
       "551471  0.0045  0.0045  0.0055  0.0075  0.0095  0.0105  0.0160  0.0160   \n",
       "\n",
       "            8       9   ...      20      21      22      23      24      25  \\\n",
       "0       0.0505  0.0501  ...  0.0329  0.0272  0.0217  0.0201  0.0186  0.0188   \n",
       "1       0.0545  0.0521  ...  0.0295  0.0238  0.0185  0.0171  0.0161  0.0155   \n",
       "2       0.0145  0.0130  ...  0.0030  0.0025  0.0015  0.0020  0.0015  0.0010   \n",
       "3       0.0600  0.0435  ...  0.0180  0.0120  0.0120  0.0085  0.0080  0.0090   \n",
       "4       0.0365  0.0350  ...  0.0435  0.0370  0.0345  0.0300  0.0280  0.0340   \n",
       "...        ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "551467  0.0200  0.0240  ...  0.0495  0.0500  0.0435  0.0505  0.0435  0.0525   \n",
       "551468  0.0205  0.0245  ...  0.0495  0.0480  0.0420  0.0500  0.0430  0.0510   \n",
       "551469  0.0225  0.0265  ...  0.0485  0.0480  0.0400  0.0460  0.0415  0.0495   \n",
       "551470  0.0325  0.0375  ...  0.0365  0.0425  0.0330  0.0370  0.0325  0.0385   \n",
       "551471  0.0185  0.0220  ...  0.0505  0.0520  0.0455  0.0515  0.0440  0.0555   \n",
       "\n",
       "            26      27      28      29  \n",
       "0       0.0190  0.0177  0.0158  0.0156  \n",
       "1       0.0152  0.0141  0.0127  0.0124  \n",
       "2       0.0015  0.0010  0.0010  0.0010  \n",
       "3       0.0100  0.0075  0.0080  0.0060  \n",
       "4       0.0320  0.0315  0.0290  0.0250  \n",
       "...        ...     ...     ...     ...  \n",
       "551467  0.0500  0.0605  0.0460  0.0690  \n",
       "551468  0.0500  0.0585  0.0480  0.0655  \n",
       "551469  0.0500  0.0540  0.0485  0.0565  \n",
       "551470  0.0360  0.0350  0.0305  0.0340  \n",
       "551471  0.0510  0.0645  0.0465  0.0760  \n",
       "\n",
       "[551472 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def savitzky_golay(y, window_size, order, deriv=0, rate=1):\n",
    "    import numpy as np\n",
    "    from math import factorial\n",
    "    \n",
    "    try:\n",
    "        window_size = np.abs(np.int(window_size))\n",
    "        order = np.abs(np.int(order))\n",
    "    except ValueError:\n",
    "        raise ValueError(\"window_size and order have to be of type int\")\n",
    "    if window_size % 2 != 1 or window_size < 1:\n",
    "        raise TypeError(\"window_size size must be a positive odd number\")\n",
    "    if window_size < order + 2:\n",
    "        raise TypeError(\"window_size is too small for the polynomials order\")\n",
    "    order_range = range(order+1)\n",
    "    half_window = (window_size -1) // 2\n",
    "    # precompute coefficients\n",
    "    b = np.mat([[k**i for i in order_range] for k in range(-half_window, half_window+1)])\n",
    "    m = np.linalg.pinv(b).A[deriv] * rate**deriv * factorial(deriv)\n",
    "    # pad the signal at the extremes with\n",
    "    # values taken from the signal itself\n",
    "    firstvals = y[0] - np.abs( y[1:half_window+1][::-1] - y[0] )\n",
    "    lastvals = y[-1] + np.abs(y[-half_window-1:-1][::-1] - y[-1])\n",
    "    y = np.concatenate((firstvals, y, lastvals))\n",
    "    return np.convolve( m[::-1], y, mode='valid')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out_df = pd.read_csv('./LSTM_1+2.csv.gz',header=None)\n",
    "display(out_df)\n",
    "for i in range(len(out_df.shape)):\n",
    "    out_df.iloc[i,:] = np.round(savitzky_golay(out_df.iloc[i,:].values, 7, 2),decimals=4)\n",
    "display(out_df)\n",
    "\n",
    "out_df.to_csv('./LSTM_1+2_smoothed.csv.gz',header=None,index=None,compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe78716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
