{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b3379e7",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f7a224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "import os.path as osp\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "\n",
    "def download_dataset():\n",
    "    fnames = ['train_data.parquet','test_data.csv','items_static_metadata_full.jl',\n",
    "         'sample_submission.csv.gz ']\n",
    "    url = 'https://meli-data-challenge.s3.amazonaws.com/2021/'\n",
    "    os.makedirs('./dataset',exist_ok=True)\n",
    "    for f in fnames:\n",
    "        \n",
    "        urllib.request.urlretrieve(url+f, f'./dataset/{f}')\n",
    "\n",
    "def extract_tarfiles():\n",
    "    import tarfile\n",
    "    for k,v in urls.items():\n",
    "        tar = tarfile.open( f'./dataset/{k}.tar.gz')\n",
    "        tar.extractall('./dataset')\n",
    "        tar.close()\n",
    "        \n",
    "download_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c54a6c",
   "metadata": {},
   "source": [
    "## Process train_data.parquet, create pytorch files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad42f3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    \"\"\"\n",
    "        Read the MercadoLibre files, put everything into a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    import gc\n",
    "    from importlib import reload\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import pyarrow #Need this to read train_data.parquet\n",
    "    \"\"\"\n",
    "    1a) Read training dataset\n",
    "    \"\"\"\n",
    "    df = pd.read_parquet('./dataset/train_data.parquet')\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['fold'] = df['date'].dt.month - 2\n",
    "\n",
    "\n",
    "    \"\"\" \n",
    "    1b) Add stock column to training dataframe. \n",
    "    This will be the number of items on stock at the beginning of April.\n",
    "    Our goal is to predict how many days it will take to empty this stock\n",
    "    \"\"\"\n",
    "    test = pd.read_csv(\"./dataset/test_data.csv\", index_col=0).squeeze()\n",
    "    df['stock'] = df['sku'].map(test)\n",
    "    df['stock'] = df['stock'].fillna(-1)\n",
    "    del test\n",
    "    gc.collect()\n",
    "    \n",
    "    \"\"\"\n",
    "        1b2) Sort by sku and date, add price relative to initial price\n",
    "    \"\"\"\n",
    "    df.sort_values([\"sku\",\"date\"],inplace=True)\n",
    "    gc.collect()\n",
    "    sku_to_first_price = df.loc[:,['sku','current_price']].drop_duplicates(subset='sku',keep='first').\\\n",
    "                                set_index('sku',drop=True).squeeze()\n",
    "    gc.collect()\n",
    "    df['price_relative'] =  df['current_price'] / df['sku'].map(sku_to_first_price)\n",
    "    gc.collect()\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "        1c)Adjust the price so that everything is in USD. Also,\n",
    "        apply logarithm on prices.\n",
    "    \"\"\"\n",
    "    to_usd = {'DOL':1.0,\n",
    "              'REA':0.19,\n",
    "              'MEX':0.05,\n",
    "              'ARG':0.01\n",
    "             }\n",
    "\n",
    "    \n",
    "    df['current_price'] = df['currency'].map(to_usd) * df['current_price']\n",
    "    df['current_price'] = np.log(df['current_price'].values)\n",
    "    df['current_price'] = (df['current_price'] - df['current_price'].mean()) /df['current_price'].std()\n",
    "    df['minutes_active'] = df['minutes_active']/1440.0 \n",
    "\n",
    "    \"\"\"\n",
    "        1d) Let us convert the columns to categorical. We'll define a few maps according to the \n",
    "        specification in the competition website.\n",
    "    \"\"\"\n",
    "    maps ={\"listing_type\": {\"classic\":0,\"premium\":1},\n",
    "           \"shipping_logistic_type\": {\"fulfillment\":0,\n",
    "                                      \"cross_docking\":1,\n",
    "                                      \"drop_off\":2},\n",
    "           \"shipping_payment\":{\"free_shipping\":0,\"paid_shipping\":1},\n",
    "           \"currency\":{\"DOL\":0,\"REA\":1,\"MEX\":2,\"ARG\":3}\n",
    "          }\n",
    "    for k in maps.keys():\n",
    "        df[k] = df[k].map(maps[k])\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "        1e)Add domain id\n",
    "    \"\"\"\n",
    "    items = pd.read_json('./dataset/items_static_metadata_full.jl', lines=True)\n",
    "    items = items.reindex(items['sku'])\n",
    "    items['item_domain_id'], category_list = items['item_domain_id'].factorize()\n",
    "    items['site_id'], _ = items['site_id'].factorize()\n",
    "    items = items.loc[:,['item_domain_id','site_id']]\n",
    "    \n",
    "    \n",
    "    for k in ['item_domain_id','site_id']:\n",
    "        df[k] = df['sku'].map(items[k])\n",
    "    del items\n",
    "    gc.collect()\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = create_dataset()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b930ee71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[464801 645793  99516 ... 170355 246568  49718]\n",
      "Length of train dataset : 496197\n",
      "Length of val dataset : 55275\n",
      "Length of test dataset : 551472\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import DataLoader,Dataset,Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MeLiDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Base class representing a dataset for the competition\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, df,mode='train',validation_mode=1,precompute=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the .pt files.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        df['is_val'] = (df['sku'] % 10 == 0)\n",
    "        df.reset_index(drop=True,inplace=True)\n",
    "        self.max_domain = df['item_domain_id'].max()\n",
    "        \n",
    "        self.validation_mode = validation_mode\n",
    "        \n",
    "        #print(f\"Percentage of NA stock: {(df['stock'] < 0).mean()*100.0}\")\n",
    "        \"\"\"\n",
    "            self.skus ()\n",
    "        \"\"\"\n",
    "        if mode == 'train':\n",
    "            b = np.logical_and(df['is_val']==False,df['stock'] > 0)\n",
    "            self.skus = pd.unique(df['sku'][b])\n",
    "        elif mode == 'val':\n",
    "            b = np.logical_and(df['is_val']==True,df['stock'] > 0)\n",
    "            self.skus = pd.unique(df['sku'][b])\n",
    "        else:\n",
    "            test_data = pd.read_csv('./dataset/test_data.csv')\n",
    "            self.skus = test_data['sku'].values\n",
    "            print(self.skus)\n",
    "        \n",
    "        \n",
    "        self.df = df\n",
    "        self.mode = mode\n",
    "        gc.collect()\n",
    "        self.inds = {}\n",
    "        \n",
    "        for which in ['first','last']:\n",
    "            self.inds[which] = df['sku'].drop_duplicates(keep=which)\\\n",
    "                                               .squeeze().to_dict()\n",
    "            inc = 1 if which == 'last' else 0\n",
    "            \n",
    "            self.inds[which] = dict([(v,k+inc) for k,v in self.inds[which].items()])\n",
    "        \n",
    "        self.precompute = precompute\n",
    "        if precompute == True:\n",
    "            self.L =  len(self.skus) * [None]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.skus)\n",
    "    \n",
    "    def convert_to_accumulative(self,days_to_stockout,total_days=30):\n",
    "        target = torch.zeros(total_days).cuda()\n",
    "        target[days_to_stockout] = 1.0\n",
    "        return torch.cumsum(target,dim=0).view(1,total_days)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        og_idx = idx\n",
    "        if self.precompute and (not self.L[og_idx] is None):\n",
    "            return self.L[og_idx]\n",
    "        \n",
    "        idx = self.skus[idx]\n",
    "        first, last = self.inds['first'][idx], self.inds['last'][idx]\n",
    "        df = self.df.iloc[first:last,:].copy()\n",
    "        df['dotw'] = (df['date'].dt.dayofweek.values)/6.0 - 0.5\n",
    "        \n",
    "        doms = np.array(df['item_domain_id'].values)\n",
    "        doms[df['item_domain_id'] < 0] = self.max_domain+1\n",
    "        df['item_domain_id'] = doms\n",
    "        df['item_domain_id'] = df['item_domain_id'].fillna(self.max_domain+1)\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            \"\"\"\n",
    "                We can use the \"stock\" attribute. The test date begins Thursday, 1st Apr\n",
    "            \"\"\"\n",
    "            stock = df['stock'].values[0]\n",
    "            assert stock > 0\n",
    "            \n",
    "            val_end = pd.to_datetime('2021-03-31T00:00:00.000000000')\n",
    "            is_train =  (val_end - pd.to_datetime(df['date'])).dt.days < 24\n",
    "            train = df[is_train].copy()\n",
    "            \n",
    "        else:\n",
    "            \"\"\" the training data is [1st Feb, 24th Feb, wednesday].\n",
    "                the validation data is [25th Feb - thursday, 31st of March]\n",
    "            \"\"\"\n",
    "            train_init = pd.to_datetime('2021-02-01T00:00:00.000000000')\n",
    "            val_init = pd.to_datetime('2021-02-25T00:00:00.000000000')\n",
    "            \n",
    "            is_train =  (pd.to_datetime(df['date']) - train_init).dt.days < 24\n",
    "            is_val = ~is_train & (( pd.to_datetime(df['date']) - val_init ).dt.days < 30)\n",
    "            train = df[is_train].copy()\n",
    "            val = df[is_val].copy()\n",
    "            val['days_passed'] =  (pd.to_datetime(df['date']) - val_init).dt.days\n",
    "            val['cumsum'] = val['sold_quantity'].cumsum()\n",
    "            \n",
    "            if (train.shape[0]==0) or (not val.shape[0] == 30) or (val['cumsum'].values[0] ==val['cumsum'].values[-1]):\n",
    "                \"\"\"\n",
    "                    Useless sample for validation. Return some other (hopefully good sample instead)\n",
    "                \"\"\"\n",
    "                #print(\"bad\")\n",
    "                return self.__getitem__(np.random.randint(10))\n",
    "            \n",
    "            if df['stock'].values[0] < 0:\n",
    "                \"\"\" We take the last day with nonzero sold quantity.\n",
    "                    Then, the stock is the amount of items sold from the \n",
    "                    beginning of the validation month till this day.\n",
    "                \"\"\"\n",
    "                return self.__getitem__(np.random.randint(10))\n",
    "            else:\n",
    "                \"\"\" The stock is the same as given in the test data. If our\n",
    "                    task in the test data is to predict how long till x units of\n",
    "                    product y are sold, then we count how many days in the validation\n",
    "                    month it took to produce that amount.\n",
    "                \"\"\"\n",
    "                stock = df['stock'].values[0]\n",
    "                if val[val['cumsum']>=stock].shape[0] == 0:\n",
    "                    return self.__getitem__(np.random.randint(self.__len__()))\n",
    "                \n",
    "                days_to_stockout = int(val[val['cumsum']>=stock]\\\n",
    "                                    ['days_passed'].values[0])\n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "        train['log_stock'] = np.log(stock) #Add a column encoding stock??    \n",
    "\n",
    "        data = Data()\n",
    "        data_cols = [k for k in train.columns if not k in ['sku','stock','date','fold','is_val','item_domain_id'] ]\n",
    "        #print(data_cols)\n",
    "        for c in data_cols:\n",
    "            data[c] =  torch.as_tensor(train[c].values).cuda()\n",
    "            \n",
    "        \n",
    "        data.shipping_logistic_type = F.one_hot(data.shipping_logistic_type,3)\n",
    "        data.currency = F.one_hot(data.currency,4)\n",
    "        data.sold_quantity = torch.clip((data.sold_quantity /  stock),0.0,1.0)\n",
    "        def maybe_squeeze(x):\n",
    "            if len(list(x.shape))==1:\n",
    "                return x.unsqueeze(-1)\n",
    "            else:\n",
    "                return x\n",
    "        data.X  = torch.cat([maybe_squeeze(getattr(data,c)) for c in data_cols],axis=1)\n",
    "        for c in data_cols:\n",
    "            delattr(data,c)\n",
    "        data.domain = torch.IntTensor([train['item_domain_id'].values]).cuda().view(-1,1)\n",
    "        data.sku = torch.IntTensor(train['sku'].values).cuda().view(-1,1)\n",
    "        \n",
    "        \"\"\"\n",
    "            Add padding to X, domain, sku. Also add extra dimension at the beginning\n",
    "        \"\"\"\n",
    "        m = data.domain.shape[0]\n",
    "        for k in ['X','domain']:\n",
    "            \n",
    "            if m < 30:\n",
    "                setattr(data,k, torch.cat([getattr(data,k),\n",
    "                                    torch.zeros(30 - m,getattr(data,k).shape[-1],\n",
    "                                        device=getattr(data,k).device)],axis=0))\n",
    "            setattr(data,k,getattr(data,k).unsqueeze(0))\n",
    "        data.sku = data.sku[0]\n",
    "        \n",
    "        if not self.mode == 'test':\n",
    "            data.target = self.convert_to_accumulative(days_to_stockout)\n",
    "            data.target = data.target.float()\n",
    "            \n",
    "        data.X = data.X.float()\n",
    "        data.sku = data.sku.int()\n",
    "        \n",
    "        if self.precompute:\n",
    "            self.L[og_idx] = data\n",
    "        return data    \n",
    "\n",
    "datasets = {\"train\":MeLiDataset(df,mode='train'),\n",
    "            \"val\":MeLiDataset(df,mode='val'),\n",
    "            \"test\":MeLiDataset(df,mode='test',precompute=True),\n",
    "           }\n",
    "\n",
    "batch_size = 32\n",
    "dataloaders = {\"train\":DataLoader(datasets['train'],batch_size=batch_size,shuffle=True),\n",
    "            \"val\":DataLoader(datasets['val'],batch_size=batch_size,shuffle=True),\n",
    "            \"test\":DataLoader(datasets['test'],batch_size=batch_size),\n",
    "           }\n",
    "for k in dataloaders.keys():\n",
    "    print(f\"Length of {k} dataset : {len(datasets[k])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d621c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1728/1728 [06:59<00:00,  4.12it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "dataloaders = {\"train\":DataLoader(datasets['train'],batch_size=batch_size,shuffle=False),\n",
    "            \"val\":DataLoader(datasets['val'],batch_size=batch_size,shuffle=False),\n",
    "            \"test\":DataLoader(datasets['test'],batch_size=batch_size),\n",
    "           }\n",
    "from tqdm import trange,tqdm\n",
    "for mode in ['val']:\n",
    "    for i, data in tqdm(enumerate(dataloaders[mode]),total=len(dataloaders[mode])):\n",
    "        continue\n",
    "\n",
    "    import os\n",
    "    os.makedirs('./dataset/converted',exist_ok=True)\n",
    "    torch.save([x for x in datasets[mode].L if not x is None],f'./dataset/converted/{mode}.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7d3b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([[not x is None for x in datasets[mode].L ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a523a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "dataloaders = {\"train\":DataLoader(train_L,batch_size=batch_size,shuffle=True),\n",
    "            \"val\":DataLoader(5*val_L,batch_size=batch_size,shuffle=False),\n",
    "            \"test\":DataLoader(test_L,batch_size=batch_size),\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5f2614b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4309/4309 [00:15<00:00, 282.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(551472, 30)\n",
      "[[0.001 0.004 0.009 ... 0.026 0.018 0.015]\n",
      " [0.001 0.003 0.006 ... 0.034 0.023 0.019]\n",
      " [0.084 0.174 0.135 ... 0.004 0.002 0.002]\n",
      " ...\n",
      " [0.002 0.005 0.005 ... 0.057 0.063 0.043]\n",
      " [0.029 0.034 0.04  ... 0.021 0.01  0.01 ]\n",
      " [0.002 0.003 0.003 ... 0.06  0.084 0.051]]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm,trange\n",
    "from torch.nn import MSELoss\n",
    "import numpy as np\n",
    "\n",
    "#model = ChallengeModel().cuda()\n",
    "#model.load_state_dict(torch.load('./model/LSTM2/model_25193.pt'))\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "L = []\n",
    "model.eval()\n",
    "for i,sample in tqdm(enumerate(dataloaders['test']),\n",
    "                         total=len(dataloaders['test']) ):\n",
    "    out = model(sample)\n",
    "    L.append(out.clone().detach().cpu())\n",
    "L = torch.cat(L,axis=0)\n",
    "L = L.cpu().numpy()\n",
    "L = np.round(L,decimals=3)\n",
    "print(L.shape)\n",
    "print(L)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e19ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
